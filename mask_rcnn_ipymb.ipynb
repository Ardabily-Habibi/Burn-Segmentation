{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# How to Train Detectron2 for Custom Instance Segmentation\n",
        "\n",
        "This tutorial is based on the [Detectron2 repository](https://github.com/facebookresearch/detectron2) by Facebook. This notebook shows training on **your own custom instance segmentation objects**.\n",
        "\n",
        "### Accompanying Blog Post\n",
        "\n",
        "We recommend that you follow along in this notebook while reading the blog post on [how to train Detectron2 for custom instance segmentation](https://blog.roboflow.ai/custom-detectron2-instance-segmentation/), concurrently.\n",
        "\n",
        "### Steps Covered in this Tutorial\n",
        "\n",
        "In this tutorial, we will walk through the steps required to train Detectron2 on your custom instance segmentation objects. We use a public [American Sign Language instance segmentation dataset](https://public.roboflow.ai/object-detection/bccd), which is open source and free to use. You can also use this notebook on your own data.\n",
        "\n",
        "To train our segmenter we take the following steps:\n",
        "\n",
        "* Install Detectron2 dependencies\n",
        "* Download custom instance segmentation data from Roboflow\n",
        "* Visualize Detectron2 training data\n",
        "* Write our Detectron2 Training configuration\n",
        "* Run Detectron2 training\n",
        "* Evaluate Dectron2 performance\n",
        "* Run Detectron2 inference on test images\n",
        "* Export saved Detectron2 weights for future inference\n",
        "\n",
        "### **About**\n",
        "\n",
        "[Roboflow](https://roboflow.com) enables teams to deploy custom computer vision models quickly and accurately. Convert data from to annotation format, assess dataset health, preprocess, augment, and more. It's free for your first 1000 source images.\n",
        "\n",
        "**Looking for a vision model available via API without hassle? Try Roboflow Train.**\n",
        "\n",
        "![Roboflow Wordmark](https://i.imgur.com/dcLNMhV.png)"
      ],
      "metadata": {
        "id": "q679zA-jFhuC"
      },
      "id": "q679zA-jFhuC"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLYNvDTIFKG2"
      },
      "source": [
        "# Install Roboflow and Detectron2 Pip Packages, Import Deps"
      ],
      "id": "XLYNvDTIFKG2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6o0vbv8mD9hA",
        "outputId": "59875809-a9ff-43db-8718-b059f9c4cdfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/facebookresearch/detectron2.git\n",
            "  Cloning https://github.com/facebookresearch/detectron2.git to /tmp/pip-req-build-p9ozy3ll\n",
            "  Running command git clone -q https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-p9ozy3ll\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (7.1.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (3.2.2)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (2.0.4)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (1.1.0)\n",
            "Collecting yacs>=0.1.8\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (0.8.10)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (4.64.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (2.8.0)\n",
            "Collecting fvcore<0.1.6,>=0.1.5\n",
            "  Downloading fvcore-0.1.5.post20220512.tar.gz (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 3.7 MB/s \n",
            "\u001b[?25hCollecting iopath<0.1.10,>=0.1.7\n",
            "  Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (0.16.0)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (1.3.0)\n",
            "Collecting omegaconf>=2.1\n",
            "  Downloading omegaconf-2.2.2-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 8.6 MB/s \n",
            "\u001b[?25hCollecting hydra-core>=1.1\n",
            "  Downloading hydra_core-1.2.0-py3-none-any.whl (151 kB)\n",
            "\u001b[K     |████████████████████████████████| 151 kB 66.6 MB/s \n",
            "\u001b[?25hCollecting black==22.3.0\n",
            "  Downloading black-22.3.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 59.3 MB/s \n",
            "\u001b[?25hCollecting timm\n",
            "  Downloading timm-0.6.7-py3-none-any.whl (509 kB)\n",
            "\u001b[K     |████████████████████████████████| 509 kB 73.0 MB/s \n",
            "\u001b[?25hCollecting fairscale\n",
            "  Downloading fairscale-0.4.6.tar.gz (248 kB)\n",
            "\u001b[K     |████████████████████████████████| 248 kB 74.5 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (21.3)\n",
            "Collecting mypy-extensions>=0.4.3\n",
            "  Downloading mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)\n",
            "Collecting platformdirs>=2\n",
            "  Downloading platformdirs-2.5.2-py3-none-any.whl (14 kB)\n",
            "Collecting click>=8.0.0\n",
            "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
            "\u001b[K     |████████████████████████████████| 96 kB 6.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from black==22.3.0->detectron2==0.6) (2.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/lib/python3.7/dist-packages (from black==22.3.0->detectron2==0.6) (4.1.1)\n",
            "Collecting pathspec>=0.9.0\n",
            "  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting typed-ast>=1.4.2\n",
            "  Downloading typed_ast-1.5.4-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (843 kB)\n",
            "\u001b[K     |████████████████████████████████| 843 kB 58.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from click>=8.0.0->black==22.3.0->detectron2==0.6) (4.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.21.6)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 59.6 MB/s \n",
            "\u001b[?25hCollecting antlr4-python3-runtime==4.9.*\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[K     |████████████████████████████████| 117 kB 60.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core>=1.1->detectron2==0.6) (5.9.0)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.5.1-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.6) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.6) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.6) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.6) (3.0.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->detectron2==0.6) (1.15.0)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.7/dist-packages (from fairscale->detectron2==0.6) (1.12.0+cu113)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->click>=8.0.0->black==22.3.0->detectron2==0.6) (3.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (3.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (1.35.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (3.17.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (57.4.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (1.2.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (0.37.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (0.4.6)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (1.47.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (1.8.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.6) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.6) (3.2.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm->detectron2==0.6) (0.13.0+cu113)\n",
            "Building wheels for collected packages: detectron2, fvcore, antlr4-python3-runtime, fairscale\n",
            "  Building wheel for detectron2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for detectron2: filename=detectron2-0.6-cp37-cp37m-linux_x86_64.whl size=5256032 sha256=a20576d74fad3aa5223fc2c617d4083a2f5ff33c81df68178122c743e4cd1cab\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-az4sa3xg/wheels/07/dc/32/0322cb484dbefab8b9366bfedbaff5060ac7d149d69c27ca5d\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20220512-py3-none-any.whl size=61288 sha256=c621949d98a3d0b0e28a76f9127f272cf9932a150dd2893e547f233390018bef\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/20/f9/a11a0dd63f4c13678b2a5ec488e48078756505c7777b75b29e\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144575 sha256=276766bcb06b6c5bd117d1b322eb9e9bbd8e7f6e20d1916fe5f1de22e4f1f475\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/8d/53/2af8772d9aec614e3fc65e53d4a993ad73c61daa8bbd85a873\n",
            "  Building wheel for fairscale (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairscale: filename=fairscale-0.4.6-py3-none-any.whl size=307252 sha256=c493e9c972841d34e0838c6ff00a92db2cf3c1fd5d946d56c8450a02bf8a26d6\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/4f/0b/94c29ea06dfad93260cb0377855f87b7b863312317a7f69fe7\n",
            "Successfully built detectron2 fvcore antlr4-python3-runtime fairscale\n",
            "Installing collected packages: pyyaml, portalocker, antlr4-python3-runtime, yacs, typed-ast, platformdirs, pathspec, omegaconf, mypy-extensions, iopath, click, timm, hydra-core, fvcore, fairscale, black, detectron2\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 7.1.2\n",
            "    Uninstalling click-7.1.2:\n",
            "      Successfully uninstalled click-7.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "flask 1.1.4 requires click<8.0,>=5.1, but you have click 8.1.3 which is incompatible.\u001b[0m\n",
            "Successfully installed antlr4-python3-runtime-4.9.3 black-22.3.0 click-8.1.3 detectron2-0.6 fairscale-0.4.6 fvcore-0.1.5.post20220512 hydra-core-1.2.0 iopath-0.1.9 mypy-extensions-0.4.3 omegaconf-2.2.2 pathspec-0.9.0 platformdirs-2.5.2 portalocker-2.5.1 pyyaml-6.0 timm-0.6.7 typed-ast-1.5.4 yacs-0.1.8\n"
          ]
        }
      ],
      "source": [
        "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
      ],
      "id": "6o0vbv8mD9hA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96a663b1"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import torch\n",
        "from collections import OrderedDict\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.utils.visualizer import ColorMode\n",
        "from detectron2.solver import build_lr_scheduler, build_optimizer\n",
        "from detectron2.checkpoint import DetectionCheckpointer, PeriodicCheckpointer\n",
        "from detectron2.utils.events import EventStorage\n",
        "from detectron2.modeling import build_model\n",
        "import detectron2.utils.comm as comm\n",
        "from detectron2.engine import default_argument_parser, default_setup, default_writers, launch\n",
        "from detectron2.data import (\n",
        "    MetadataCatalog,\n",
        "    build_detection_test_loader,\n",
        "    build_detection_train_loader,\n",
        ")\n",
        "from detectron2.evaluation import (\n",
        "    CityscapesInstanceEvaluator,\n",
        "    CityscapesSemSegEvaluator,\n",
        "    COCOEvaluator,\n",
        "    COCOPanopticEvaluator,\n",
        "    DatasetEvaluators,\n",
        "    LVISEvaluator,\n",
        "    PascalVOCDetectionEvaluator,\n",
        "    SemSegEvaluator,\n",
        "    inference_on_dataset,\n",
        "    print_csv_format,\n",
        ")\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image"
      ],
      "id": "96a663b1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuYKkvDhBofX",
        "outputId": "f0de0ce8-909c-42e8-d753-7a1bbafa8711"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "TuYKkvDhBofX"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnbQ638KFraT"
      },
      "source": [
        "# Download dataset via Roboflow pip package and show a sample annotation"
      ],
      "id": "NnbQ638KFraT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bXEDiF3Jt8K"
      },
      "outputs": [],
      "source": [
        "from detectron2.data.datasets import register_coco_instances\n",
        "\n",
        "register_coco_instances(f\"Train\", {}, f\"/content/drive/MyDrive/Dataset_v4/train.json\", f\"/content/drive/MyDrive/Dataset_v4/train\")\n",
        "register_coco_instances(f\"Test\", {}, f\"/content/drive/MyDrive/Dataset_v4/test.json\", f\"/content/drive/MyDrive/Dataset_v4/test\")"
      ],
      "id": "4bXEDiF3Jt8K"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "025469d5"
      },
      "outputs": [],
      "source": [
        "import PIL\n",
        "print(PIL.PILLOW_VERSION)\n",
        "dataset_train = DatasetCatalog.get(\"Train\")\n",
        "fig, ax = plt.subplots()\n",
        "dataset_dict = random.choice(dataset_train)\n",
        "im = Image.open(dataset_dict['file_name'])\n",
        "ax.imshow(im)\n",
        "for ann in dataset_dict['annotations']:\n",
        "    for poly in ann['segmentation']:\n",
        "        x = poly[0::2]\n",
        "        y = poly[1::2]\n",
        "        ax.plot(x,y, linewidth=2, color='red')"
      ],
      "id": "025469d5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ykg6JSdFzUa"
      },
      "source": [
        "# Configure Detectron2 for fine tuning from COCO, Define training loop helper functions (from detectron2 repo), Run custom training loop"
      ],
      "id": "5Ykg6JSdFzUa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ff170f2"
      },
      "outputs": [],
      "source": [
        "cfg = get_cfg()\n",
        "cfg.MODEL.DEVICE = \"cuda\"\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\"))\n",
        "cfg.DATASETS.TRAIN = (\"Train\",)#Train dataset registered in a previous cell\n",
        "cfg.DATASETS.TEST = (\"Test\",)#Test dataset registered in a previous cell\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2\n",
        "cfg.SOLVER.BASE_LR = 0.00025\n",
        "cfg.SOLVER.MAX_ITER = 20000 #We found that with a patience of 500, training will early stop before 10,000 iterations\n",
        "cfg.SOLVER.STEPS = []\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3 # 26 letters plus one super class\n",
        "cfg.TEST.EVAL_PERIOD = 0 # Increase this number if you want to monitor validation performance during training\n",
        "cfg.SEED = 300\n",
        "\n",
        "PATIENCE = 2000 #Early stopping will occur after N iterations of no imporovement in total_loss\n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)"
      ],
      "id": "2ff170f2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "043e9caa",
        "outputId": "66307f2c-3691-4f1f-e564-fbc489775dd7"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model_final_2d9806.pkl: 431MB [00:12, 34.4MB/s]                           \n",
            "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (12, 1024) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (12,) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (3, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
            "Some model parameters or buffers are not found in the checkpoint:\n",
            "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
            "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
            "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/31 10:17:59 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[07/31 10:17:59 d2.data.datasets.coco]: \u001b[0mLoaded 92 images in COCO format from /content/drive/MyDrive/Dataset_v4/train.json\n",
            "\u001b[32m[07/31 10:17:59 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 92 images left.\n",
            "\u001b[32m[07/31 10:17:59 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
            "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
            "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
            "| derajat 1  | 22           | derajat 2  | 166          | derajat 3  | 86           |\n",
            "|            |              |            |              |            |              |\n",
            "|   total    | 274          |            |              |            |              |\u001b[0m\n",
            "\u001b[32m[07/31 10:17:59 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[07/31 10:17:59 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "\u001b[32m[07/31 10:17:59 d2.data.common]: \u001b[0mSerializing 92 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/31 10:17:59 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[32m[07/31 10:17:59 detectron2]: \u001b[0mStarting training from iteration 0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m[07/31 10:18:46 d2.utils.events]: \u001b[0m iter: 19  total_loss: 2.444  loss_cls: 1.388  loss_box_reg: 0.1611  loss_mask: 0.6926  loss_rpn_cls: 0.1778  loss_rpn_loc: 0.03279  lr: 4.9953e-06  max_mem: 6286M\n",
            "\u001b[32m[07/31 10:19:17 d2.utils.events]: \u001b[0m eta: 8:30:42  iter: 39  total_loss: 2.24  loss_cls: 1.242  loss_box_reg: 0.1329  loss_mask: 0.691  loss_rpn_cls: 0.1366  loss_rpn_loc: 0.02414  lr: 9.9902e-06  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:19:55 d2.utils.events]: \u001b[0m eta: 10:44:00  iter: 59  total_loss: 1.972  loss_cls: 0.9396  loss_box_reg: 0.141  loss_mask: 0.6867  loss_rpn_cls: 0.1406  loss_rpn_loc: 0.02174  lr: 1.4985e-05  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:20:29 d2.utils.events]: \u001b[0m eta: 9:12:34  iter: 79  total_loss: 1.651  loss_cls: 0.6804  loss_box_reg: 0.1598  loss_mask: 0.6837  loss_rpn_cls: 0.1367  loss_rpn_loc: 0.02629  lr: 1.998e-05  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:20:59 d2.utils.events]: \u001b[0m eta: 8:31:26  iter: 99  total_loss: 1.449  loss_cls: 0.4589  loss_box_reg: 0.2066  loss_mask: 0.6775  loss_rpn_cls: 0.07648  loss_rpn_loc: 0.02651  lr: 2.4975e-05  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:21:26 d2.utils.events]: \u001b[0m eta: 7:27:28  iter: 119  total_loss: 1.301  loss_cls: 0.3474  loss_box_reg: 0.1666  loss_mask: 0.6671  loss_rpn_cls: 0.07293  loss_rpn_loc: 0.02842  lr: 2.997e-05  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:22:03 d2.utils.events]: \u001b[0m eta: 10:13:22  iter: 139  total_loss: 1.169  loss_cls: 0.2858  loss_box_reg: 0.1628  loss_mask: 0.6542  loss_rpn_cls: 0.04281  loss_rpn_loc: 0.02061  lr: 3.4965e-05  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:22:36 d2.utils.events]: \u001b[0m eta: 9:00:49  iter: 159  total_loss: 1.233  loss_cls: 0.2977  loss_box_reg: 0.2436  loss_mask: 0.6442  loss_rpn_cls: 0.04216  loss_rpn_loc: 0.02481  lr: 3.996e-05  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:23:00 d2.utils.events]: \u001b[0m eta: 6:29:09  iter: 179  total_loss: 1.148  loss_cls: 0.2554  loss_box_reg: 0.2225  loss_mask: 0.6268  loss_rpn_cls: 0.03348  loss_rpn_loc: 0.01934  lr: 4.4955e-05  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:23:31 d2.utils.events]: \u001b[0m eta: 8:33:42  iter: 199  total_loss: 1.155  loss_cls: 0.2569  loss_box_reg: 0.1963  loss_mask: 0.614  loss_rpn_cls: 0.02276  loss_rpn_loc: 0.01849  lr: 4.995e-05  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:23:57 d2.utils.events]: \u001b[0m eta: 7:07:48  iter: 219  total_loss: 1.128  loss_cls: 0.2381  loss_box_reg: 0.212  loss_mask: 0.5951  loss_rpn_cls: 0.02145  loss_rpn_loc: 0.02044  lr: 5.4945e-05  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:24:20 d2.utils.events]: \u001b[0m eta: 6:27:55  iter: 239  total_loss: 1.068  loss_cls: 0.2494  loss_box_reg: 0.2531  loss_mask: 0.5708  loss_rpn_cls: 0.03002  loss_rpn_loc: 0.02303  lr: 5.994e-05  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:24:47 d2.utils.events]: \u001b[0m eta: 7:11:48  iter: 259  total_loss: 0.9966  loss_cls: 0.2088  loss_box_reg: 0.2074  loss_mask: 0.563  loss_rpn_cls: 0.02497  loss_rpn_loc: 0.01946  lr: 6.4935e-05  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:25:13 d2.utils.events]: \u001b[0m eta: 7:04:49  iter: 279  total_loss: 1.014  loss_cls: 0.2229  loss_box_reg: 0.224  loss_mask: 0.5339  loss_rpn_cls: 0.01925  loss_rpn_loc: 0.01671  lr: 6.993e-05  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:25:39 d2.utils.events]: \u001b[0m eta: 7:11:16  iter: 299  total_loss: 0.9528  loss_cls: 0.2215  loss_box_reg: 0.2251  loss_mask: 0.4698  loss_rpn_cls: 0.0186  loss_rpn_loc: 0.01715  lr: 7.4925e-05  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:26:06 d2.utils.events]: \u001b[0m eta: 7:21:59  iter: 319  total_loss: 1.047  loss_cls: 0.254  loss_box_reg: 0.2615  loss_mask: 0.4992  loss_rpn_cls: 0.01212  loss_rpn_loc: 0.01917  lr: 7.992e-05  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:26:35 d2.utils.events]: \u001b[0m eta: 7:53:58  iter: 339  total_loss: 1.054  loss_cls: 0.2523  loss_box_reg: 0.2721  loss_mask: 0.454  loss_rpn_cls: 0.01854  loss_rpn_loc: 0.01893  lr: 8.4915e-05  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:27:07 d2.utils.events]: \u001b[0m eta: 8:54:10  iter: 359  total_loss: 0.8839  loss_cls: 0.2078  loss_box_reg: 0.2344  loss_mask: 0.4198  loss_rpn_cls: 0.01385  loss_rpn_loc: 0.01661  lr: 8.991e-05  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:27:32 d2.utils.events]: \u001b[0m eta: 6:46:22  iter: 379  total_loss: 0.9431  loss_cls: 0.2408  loss_box_reg: 0.2924  loss_mask: 0.3877  loss_rpn_cls: 0.01085  loss_rpn_loc: 0.02072  lr: 9.4905e-05  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:27:58 d2.utils.events]: \u001b[0m eta: 7:01:21  iter: 399  total_loss: 0.8942  loss_cls: 0.2026  loss_box_reg: 0.2747  loss_mask: 0.3804  loss_rpn_cls: 0.02064  loss_rpn_loc: 0.01361  lr: 9.99e-05  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:28:22 d2.utils.events]: \u001b[0m eta: 6:39:16  iter: 419  total_loss: 0.8445  loss_cls: 0.2053  loss_box_reg: 0.2346  loss_mask: 0.3689  loss_rpn_cls: 0.0158  loss_rpn_loc: 0.01718  lr: 0.0001049  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:28:46 d2.utils.events]: \u001b[0m eta: 6:22:48  iter: 439  total_loss: 1.049  loss_cls: 0.2761  loss_box_reg: 0.3344  loss_mask: 0.372  loss_rpn_cls: 0.01653  loss_rpn_loc: 0.01746  lr: 0.00010989  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:29:13 d2.utils.events]: \u001b[0m eta: 7:16:27  iter: 459  total_loss: 0.8068  loss_cls: 0.1873  loss_box_reg: 0.2557  loss_mask: 0.3226  loss_rpn_cls: 0.01116  loss_rpn_loc: 0.01492  lr: 0.00011489  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:29:42 d2.utils.events]: \u001b[0m eta: 8:01:40  iter: 479  total_loss: 0.7748  loss_cls: 0.1701  loss_box_reg: 0.2264  loss_mask: 0.313  loss_rpn_cls: 0.008036  loss_rpn_loc: 0.01326  lr: 0.00011988  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:30:10 d2.utils.events]: \u001b[0m eta: 7:29:20  iter: 499  total_loss: 0.9198  loss_cls: 0.2143  loss_box_reg: 0.3019  loss_mask: 0.3002  loss_rpn_cls: 0.01304  loss_rpn_loc: 0.01609  lr: 0.00012488  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:30:33 d2.utils.events]: \u001b[0m eta: 6:21:25  iter: 519  total_loss: 0.8724  loss_cls: 0.1959  loss_box_reg: 0.281  loss_mask: 0.2956  loss_rpn_cls: 0.007022  loss_rpn_loc: 0.01485  lr: 0.00012987  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:30:57 d2.utils.events]: \u001b[0m eta: 6:17:07  iter: 539  total_loss: 0.9171  loss_cls: 0.2314  loss_box_reg: 0.3692  loss_mask: 0.2379  loss_rpn_cls: 0.004856  loss_rpn_loc: 0.01273  lr: 0.00013487  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:31:20 d2.utils.events]: \u001b[0m eta: 6:22:52  iter: 559  total_loss: 0.7496  loss_cls: 0.166  loss_box_reg: 0.2952  loss_mask: 0.2602  loss_rpn_cls: 0.01012  loss_rpn_loc: 0.01266  lr: 0.00013986  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:31:46 d2.utils.events]: \u001b[0m eta: 6:47:42  iter: 579  total_loss: 0.7973  loss_cls: 0.1876  loss_box_reg: 0.2907  loss_mask: 0.2555  loss_rpn_cls: 0.004585  loss_rpn_loc: 0.01529  lr: 0.00014486  max_mem: 6288M\n",
            "Loss has not improved for 100 iterations\n",
            "\u001b[32m[07/31 10:32:10 d2.utils.events]: \u001b[0m eta: 6:35:06  iter: 599  total_loss: 0.6537  loss_cls: 0.1436  loss_box_reg: 0.2041  loss_mask: 0.2637  loss_rpn_cls: 0.002622  loss_rpn_loc: 0.01118  lr: 0.00014985  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:32:37 d2.utils.events]: \u001b[0m eta: 7:08:46  iter: 619  total_loss: 0.6891  loss_cls: 0.1832  loss_box_reg: 0.253  loss_mask: 0.2219  loss_rpn_cls: 0.006536  loss_rpn_loc: 0.01113  lr: 0.00015485  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:33:00 d2.utils.events]: \u001b[0m eta: 6:23:06  iter: 639  total_loss: 0.647  loss_cls: 0.1447  loss_box_reg: 0.2604  loss_mask: 0.2284  loss_rpn_cls: 0.009444  loss_rpn_loc: 0.01362  lr: 0.00015984  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:33:24 d2.utils.events]: \u001b[0m eta: 6:23:53  iter: 659  total_loss: 0.7666  loss_cls: 0.1999  loss_box_reg: 0.2586  loss_mask: 0.2507  loss_rpn_cls: 0.00381  loss_rpn_loc: 0.01341  lr: 0.00016484  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:33:49 d2.utils.events]: \u001b[0m eta: 6:33:17  iter: 679  total_loss: 0.6775  loss_cls: 0.1695  loss_box_reg: 0.2668  loss_mask: 0.2408  loss_rpn_cls: 0.002999  loss_rpn_loc: 0.0139  lr: 0.00016983  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:34:13 d2.utils.events]: \u001b[0m eta: 6:30:36  iter: 699  total_loss: 0.555  loss_cls: 0.1387  loss_box_reg: 0.1933  loss_mask: 0.2374  loss_rpn_cls: 0.003158  loss_rpn_loc: 0.01392  lr: 0.00017483  max_mem: 6288M\n",
            "Loss has not improved for 100 iterations\n",
            "\u001b[32m[07/31 10:34:37 d2.utils.events]: \u001b[0m eta: 6:29:04  iter: 719  total_loss: 0.5327  loss_cls: 0.1436  loss_box_reg: 0.191  loss_mask: 0.1945  loss_rpn_cls: 0.001753  loss_rpn_loc: 0.01534  lr: 0.00017982  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:35:03 d2.utils.events]: \u001b[0m eta: 6:54:28  iter: 739  total_loss: 0.5909  loss_cls: 0.1398  loss_box_reg: 0.2142  loss_mask: 0.2315  loss_rpn_cls: 0.003005  loss_rpn_loc: 0.0137  lr: 0.00018482  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:35:31 d2.utils.events]: \u001b[0m eta: 7:25:01  iter: 759  total_loss: 0.645  loss_cls: 0.1571  loss_box_reg: 0.2374  loss_mask: 0.2292  loss_rpn_cls: 0.001108  loss_rpn_loc: 0.01548  lr: 0.00018981  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:35:55 d2.utils.events]: \u001b[0m eta: 6:28:04  iter: 779  total_loss: 0.5381  loss_cls: 0.1249  loss_box_reg: 0.1819  loss_mask: 0.1745  loss_rpn_cls: 0.001838  loss_rpn_loc: 0.01036  lr: 0.00019481  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:36:27 d2.utils.events]: \u001b[0m eta: 8:28:15  iter: 799  total_loss: 0.4674  loss_cls: 0.09537  loss_box_reg: 0.1481  loss_mask: 0.1958  loss_rpn_cls: 0.0005746  loss_rpn_loc: 0.009802  lr: 0.0001998  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:36:52 d2.utils.events]: \u001b[0m eta: 6:39:04  iter: 819  total_loss: 0.5931  loss_cls: 0.121  loss_box_reg: 0.2043  loss_mask: 0.2162  loss_rpn_cls: 0.002603  loss_rpn_loc: 0.01261  lr: 0.0002048  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:37:19 d2.utils.events]: \u001b[0m eta: 7:15:52  iter: 839  total_loss: 0.4822  loss_cls: 0.1035  loss_box_reg: 0.1382  loss_mask: 0.1999  loss_rpn_cls: 0.00111  loss_rpn_loc: 0.01195  lr: 0.00020979  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:37:43 d2.utils.events]: \u001b[0m eta: 6:25:23  iter: 859  total_loss: 0.4122  loss_cls: 0.08169  loss_box_reg: 0.1321  loss_mask: 0.1733  loss_rpn_cls: 0.000417  loss_rpn_loc: 0.01014  lr: 0.00021479  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:38:09 d2.utils.events]: \u001b[0m eta: 6:52:51  iter: 879  total_loss: 0.5275  loss_cls: 0.1178  loss_box_reg: 0.171  loss_mask: 0.2074  loss_rpn_cls: 0.0003163  loss_rpn_loc: 0.01188  lr: 0.00021978  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:38:36 d2.utils.events]: \u001b[0m eta: 7:14:18  iter: 899  total_loss: 0.4023  loss_cls: 0.08762  loss_box_reg: 0.1196  loss_mask: 0.1721  loss_rpn_cls: 0.0007766  loss_rpn_loc: 0.008208  lr: 0.00022478  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:39:01 d2.utils.events]: \u001b[0m eta: 6:26:16  iter: 919  total_loss: 0.4706  loss_cls: 0.08937  loss_box_reg: 0.1687  loss_mask: 0.1967  loss_rpn_cls: 0.0006788  loss_rpn_loc: 0.01092  lr: 0.00022977  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:39:25 d2.utils.events]: \u001b[0m eta: 6:27:07  iter: 939  total_loss: 0.4083  loss_cls: 0.0858  loss_box_reg: 0.1342  loss_mask: 0.1519  loss_rpn_cls: 0.0001477  loss_rpn_loc: 0.008365  lr: 0.00023477  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:39:47 d2.utils.events]: \u001b[0m eta: 5:43:49  iter: 959  total_loss: 0.3802  loss_cls: 0.08048  loss_box_reg: 0.1141  loss_mask: 0.1702  loss_rpn_cls: 0.0004625  loss_rpn_loc: 0.007348  lr: 0.00023976  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:40:12 d2.utils.events]: \u001b[0m eta: 6:35:17  iter: 979  total_loss: 0.3644  loss_cls: 0.07072  loss_box_reg: 0.1199  loss_mask: 0.1713  loss_rpn_cls: 0.0002693  loss_rpn_loc: 0.008331  lr: 0.00024476  max_mem: 6288M\n",
            "Loss has not improved for 100 iterations\n",
            "\u001b[32m[07/31 10:40:37 d2.utils.events]: \u001b[0m eta: 6:36:11  iter: 999  total_loss: 0.3829  loss_cls: 0.07899  loss_box_reg: 0.1208  loss_mask: 0.1665  loss_rpn_cls: 0.0008549  loss_rpn_loc: 0.009462  lr: 0.00024975  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:41:00 d2.utils.events]: \u001b[0m eta: 6:14:34  iter: 1019  total_loss: 0.4557  loss_cls: 0.09975  loss_box_reg: 0.134  loss_mask: 0.1801  loss_rpn_cls: 0.0004731  loss_rpn_loc: 0.01073  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:41:25 d2.utils.events]: \u001b[0m eta: 6:28:29  iter: 1039  total_loss: 0.36  loss_cls: 0.06462  loss_box_reg: 0.09575  loss_mask: 0.1583  loss_rpn_cls: 0.0002137  loss_rpn_loc: 0.008137  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:41:49 d2.utils.events]: \u001b[0m eta: 6:27:38  iter: 1059  total_loss: 0.3972  loss_cls: 0.08945  loss_box_reg: 0.1325  loss_mask: 0.1756  loss_rpn_cls: 0.0004786  loss_rpn_loc: 0.01344  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:42:14 d2.utils.events]: \u001b[0m eta: 6:21:13  iter: 1079  total_loss: 0.3689  loss_cls: 0.06807  loss_box_reg: 0.09962  loss_mask: 0.176  loss_rpn_cls: 0.0002427  loss_rpn_loc: 0.009171  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:42:45 d2.utils.events]: \u001b[0m eta: 8:10:06  iter: 1099  total_loss: 0.4153  loss_cls: 0.07625  loss_box_reg: 0.1357  loss_mask: 0.1628  loss_rpn_cls: 0.0001803  loss_rpn_loc: 0.01024  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:43:08 d2.utils.events]: \u001b[0m eta: 6:13:12  iter: 1119  total_loss: 0.3189  loss_cls: 0.06092  loss_box_reg: 0.1054  loss_mask: 0.1427  loss_rpn_cls: 0.0002788  loss_rpn_loc: 0.00799  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:43:32 d2.utils.events]: \u001b[0m eta: 6:07:04  iter: 1139  total_loss: 0.3868  loss_cls: 0.07032  loss_box_reg: 0.1189  loss_mask: 0.1757  loss_rpn_cls: 0.0008133  loss_rpn_loc: 0.009254  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:43:55 d2.utils.events]: \u001b[0m eta: 6:07:46  iter: 1159  total_loss: 0.2975  loss_cls: 0.06469  loss_box_reg: 0.09794  loss_mask: 0.1345  loss_rpn_cls: 5.641e-05  loss_rpn_loc: 0.007067  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:44:18 d2.utils.events]: \u001b[0m eta: 6:04:06  iter: 1179  total_loss: 0.3639  loss_cls: 0.06538  loss_box_reg: 0.1096  loss_mask: 0.1575  loss_rpn_cls: 5.657e-05  loss_rpn_loc: 0.008985  lr: 0.00025  max_mem: 6288M\n",
            "Loss has not improved for 100 iterations\n",
            "\u001b[32m[07/31 10:44:43 d2.utils.events]: \u001b[0m eta: 6:31:08  iter: 1199  total_loss: 0.3542  loss_cls: 0.07297  loss_box_reg: 0.1105  loss_mask: 0.1598  loss_rpn_cls: 0.0002021  loss_rpn_loc: 0.009057  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:45:08 d2.utils.events]: \u001b[0m eta: 6:23:41  iter: 1219  total_loss: 0.3413  loss_cls: 0.05689  loss_box_reg: 0.1023  loss_mask: 0.1799  loss_rpn_cls: 0.0004433  loss_rpn_loc: 0.00895  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:45:36 d2.utils.events]: \u001b[0m eta: 7:13:14  iter: 1239  total_loss: 0.3403  loss_cls: 0.05783  loss_box_reg: 0.1163  loss_mask: 0.1453  loss_rpn_cls: 0.0001053  loss_rpn_loc: 0.009057  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:45:59 d2.utils.events]: \u001b[0m eta: 5:59:56  iter: 1259  total_loss: 0.3168  loss_cls: 0.06094  loss_box_reg: 0.08867  loss_mask: 0.1691  loss_rpn_cls: 0.0001367  loss_rpn_loc: 0.008791  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:46:24 d2.utils.events]: \u001b[0m eta: 6:32:01  iter: 1279  total_loss: 0.332  loss_cls: 0.05543  loss_box_reg: 0.1051  loss_mask: 0.1443  loss_rpn_cls: 0.0005331  loss_rpn_loc: 0.01153  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:46:47 d2.utils.events]: \u001b[0m eta: 6:03:15  iter: 1299  total_loss: 0.3114  loss_cls: 0.05466  loss_box_reg: 0.09582  loss_mask: 0.1514  loss_rpn_cls: 9.647e-05  loss_rpn_loc: 0.007571  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:47:14 d2.utils.events]: \u001b[0m eta: 7:00:34  iter: 1319  total_loss: 0.3875  loss_cls: 0.07202  loss_box_reg: 0.1356  loss_mask: 0.1589  loss_rpn_cls: 9.813e-05  loss_rpn_loc: 0.01211  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:47:38 d2.utils.events]: \u001b[0m eta: 6:12:53  iter: 1339  total_loss: 0.2788  loss_cls: 0.04436  loss_box_reg: 0.08976  loss_mask: 0.1306  loss_rpn_cls: 3.481e-05  loss_rpn_loc: 0.006953  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:48:02 d2.utils.events]: \u001b[0m eta: 6:10:10  iter: 1359  total_loss: 0.2805  loss_cls: 0.04575  loss_box_reg: 0.07012  loss_mask: 0.148  loss_rpn_cls: 4.545e-05  loss_rpn_loc: 0.005964  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:48:26 d2.utils.events]: \u001b[0m eta: 6:13:28  iter: 1379  total_loss: 0.3283  loss_cls: 0.05224  loss_box_reg: 0.09868  loss_mask: 0.1501  loss_rpn_cls: 0.0001003  loss_rpn_loc: 0.009191  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:48:50 d2.utils.events]: \u001b[0m eta: 6:18:52  iter: 1399  total_loss: 0.3992  loss_cls: 0.07664  loss_box_reg: 0.1329  loss_mask: 0.1724  loss_rpn_cls: 4.694e-05  loss_rpn_loc: 0.01202  lr: 0.00025  max_mem: 6288M\n",
            "Loss has not improved for 100 iterations\n",
            "\u001b[32m[07/31 10:49:16 d2.utils.events]: \u001b[0m eta: 6:30:13  iter: 1419  total_loss: 0.2474  loss_cls: 0.03658  loss_box_reg: 0.06427  loss_mask: 0.127  loss_rpn_cls: 3.262e-05  loss_rpn_loc: 0.005566  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:49:39 d2.utils.events]: \u001b[0m eta: 6:08:46  iter: 1439  total_loss: 0.2782  loss_cls: 0.0411  loss_box_reg: 0.09084  loss_mask: 0.1351  loss_rpn_cls: 7.035e-05  loss_rpn_loc: 0.006781  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:50:03 d2.utils.events]: \u001b[0m eta: 6:10:20  iter: 1459  total_loss: 0.2964  loss_cls: 0.05196  loss_box_reg: 0.06811  loss_mask: 0.1566  loss_rpn_cls: 6.509e-05  loss_rpn_loc: 0.008373  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:50:29 d2.utils.events]: \u001b[0m eta: 6:29:49  iter: 1479  total_loss: 0.3007  loss_cls: 0.05394  loss_box_reg: 0.09739  loss_mask: 0.147  loss_rpn_cls: 0.0003014  loss_rpn_loc: 0.007895  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:50:56 d2.utils.events]: \u001b[0m eta: 7:04:14  iter: 1499  total_loss: 0.2823  loss_cls: 0.04522  loss_box_reg: 0.0792  loss_mask: 0.1519  loss_rpn_cls: 4.47e-05  loss_rpn_loc: 0.00752  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:51:22 d2.utils.events]: \u001b[0m eta: 6:38:50  iter: 1519  total_loss: 0.2706  loss_cls: 0.04475  loss_box_reg: 0.08405  loss_mask: 0.1578  loss_rpn_cls: 0.0005747  loss_rpn_loc: 0.01116  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:51:46 d2.utils.events]: \u001b[0m eta: 6:11:29  iter: 1539  total_loss: 0.2473  loss_cls: 0.04085  loss_box_reg: 0.07359  loss_mask: 0.1349  loss_rpn_cls: 5.111e-05  loss_rpn_loc: 0.005082  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:52:11 d2.utils.events]: \u001b[0m eta: 6:15:28  iter: 1559  total_loss: 0.281  loss_cls: 0.04094  loss_box_reg: 0.08048  loss_mask: 0.1336  loss_rpn_cls: 0.0001031  loss_rpn_loc: 0.008066  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:52:34 d2.utils.events]: \u001b[0m eta: 5:51:39  iter: 1579  total_loss: 0.31  loss_cls: 0.04818  loss_box_reg: 0.08059  loss_mask: 0.167  loss_rpn_cls: 4.054e-05  loss_rpn_loc: 0.007965  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:53:03 d2.utils.events]: \u001b[0m eta: 7:37:38  iter: 1599  total_loss: 0.2123  loss_cls: 0.03273  loss_box_reg: 0.06783  loss_mask: 0.1144  loss_rpn_cls: 3.582e-05  loss_rpn_loc: 0.004438  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:53:26 d2.utils.events]: \u001b[0m eta: 5:50:42  iter: 1619  total_loss: 0.3267  loss_cls: 0.05315  loss_box_reg: 0.104  loss_mask: 0.1403  loss_rpn_cls: 9.227e-05  loss_rpn_loc: 0.009578  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:53:50 d2.utils.events]: \u001b[0m eta: 5:55:14  iter: 1639  total_loss: 0.2876  loss_cls: 0.04993  loss_box_reg: 0.08015  loss_mask: 0.1546  loss_rpn_cls: 3.27e-05  loss_rpn_loc: 0.007461  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:54:14 d2.utils.events]: \u001b[0m eta: 6:18:26  iter: 1659  total_loss: 0.2579  loss_cls: 0.03883  loss_box_reg: 0.08316  loss_mask: 0.1314  loss_rpn_cls: 4.523e-05  loss_rpn_loc: 0.00635  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:54:41 d2.utils.events]: \u001b[0m eta: 6:52:16  iter: 1679  total_loss: 0.2276  loss_cls: 0.03402  loss_box_reg: 0.06018  loss_mask: 0.1231  loss_rpn_cls: 5.366e-05  loss_rpn_loc: 0.006843  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:55:06 d2.utils.events]: \u001b[0m eta: 6:13:35  iter: 1699  total_loss: 0.2991  loss_cls: 0.05353  loss_box_reg: 0.08823  loss_mask: 0.1449  loss_rpn_cls: 0.0003402  loss_rpn_loc: 0.006484  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:55:30 d2.utils.events]: \u001b[0m eta: 6:11:10  iter: 1719  total_loss: 0.2346  loss_cls: 0.03904  loss_box_reg: 0.07131  loss_mask: 0.132  loss_rpn_cls: 4.534e-05  loss_rpn_loc: 0.004943  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:55:59 d2.utils.events]: \u001b[0m eta: 7:11:28  iter: 1739  total_loss: 0.3374  loss_cls: 0.05139  loss_box_reg: 0.11  loss_mask: 0.1553  loss_rpn_cls: 9.385e-05  loss_rpn_loc: 0.00832  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:56:21 d2.utils.events]: \u001b[0m eta: 5:46:58  iter: 1759  total_loss: 0.2721  loss_cls: 0.0444  loss_box_reg: 0.08593  loss_mask: 0.1318  loss_rpn_cls: 2.312e-05  loss_rpn_loc: 0.009445  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:56:46 d2.utils.events]: \u001b[0m eta: 6:12:20  iter: 1779  total_loss: 0.2308  loss_cls: 0.03701  loss_box_reg: 0.06472  loss_mask: 0.1291  loss_rpn_cls: 0.0001159  loss_rpn_loc: 0.00539  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:57:11 d2.utils.events]: \u001b[0m eta: 6:18:32  iter: 1799  total_loss: 0.2646  loss_cls: 0.0384  loss_box_reg: 0.09488  loss_mask: 0.1317  loss_rpn_cls: 0.0001118  loss_rpn_loc: 0.007285  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:57:35 d2.utils.events]: \u001b[0m eta: 6:00:22  iter: 1819  total_loss: 0.2283  loss_cls: 0.03646  loss_box_reg: 0.06707  loss_mask: 0.1156  loss_rpn_cls: 3.397e-05  loss_rpn_loc: 0.005632  lr: 0.00025  max_mem: 6288M\n",
            "Loss has not improved for 100 iterations\n",
            "\u001b[32m[07/31 10:57:59 d2.utils.events]: \u001b[0m eta: 6:06:23  iter: 1839  total_loss: 0.2587  loss_cls: 0.0392  loss_box_reg: 0.08575  loss_mask: 0.1396  loss_rpn_cls: 2.354e-05  loss_rpn_loc: 0.00791  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:58:23 d2.utils.events]: \u001b[0m eta: 5:59:37  iter: 1859  total_loss: 0.2485  loss_cls: 0.04138  loss_box_reg: 0.06526  loss_mask: 0.1249  loss_rpn_cls: 0.0001291  loss_rpn_loc: 0.009761  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:58:47 d2.utils.events]: \u001b[0m eta: 6:13:15  iter: 1879  total_loss: 0.2121  loss_cls: 0.03175  loss_box_reg: 0.05643  loss_mask: 0.1197  loss_rpn_cls: 9.338e-05  loss_rpn_loc: 0.004419  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:59:11 d2.utils.events]: \u001b[0m eta: 6:02:20  iter: 1899  total_loss: 0.2959  loss_cls: 0.04377  loss_box_reg: 0.08799  loss_mask: 0.1335  loss_rpn_cls: 5.526e-05  loss_rpn_loc: 0.007689  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 10:59:36 d2.utils.events]: \u001b[0m eta: 6:11:44  iter: 1919  total_loss: 0.2218  loss_cls: 0.02649  loss_box_reg: 0.06432  loss_mask: 0.1196  loss_rpn_cls: 3.165e-05  loss_rpn_loc: 0.005842  lr: 0.00025  max_mem: 6288M\n",
            "Loss has not improved for 200 iterations\n",
            "\u001b[32m[07/31 11:00:01 d2.utils.events]: \u001b[0m eta: 6:18:25  iter: 1939  total_loss: 0.2956  loss_cls: 0.04825  loss_box_reg: 0.09639  loss_mask: 0.1448  loss_rpn_cls: 4.518e-05  loss_rpn_loc: 0.00884  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 11:00:24 d2.utils.events]: \u001b[0m eta: 5:49:39  iter: 1959  total_loss: 0.2636  loss_cls: 0.03625  loss_box_reg: 0.07612  loss_mask: 0.1406  loss_rpn_cls: 0.0002008  loss_rpn_loc: 0.0077  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 11:00:48 d2.utils.events]: \u001b[0m eta: 5:58:44  iter: 1979  total_loss: 0.2152  loss_cls: 0.03424  loss_box_reg: 0.06083  loss_mask: 0.1231  loss_rpn_cls: 1.938e-05  loss_rpn_loc: 0.005773  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 11:01:12 d2.utils.events]: \u001b[0m eta: 5:51:28  iter: 1999  total_loss: 0.2229  loss_cls: 0.03331  loss_box_reg: 0.06821  loss_mask: 0.1131  loss_rpn_cls: 2.414e-05  loss_rpn_loc: 0.005559  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 11:01:38 d2.utils.events]: \u001b[0m eta: 6:39:49  iter: 2019  total_loss: 0.2599  loss_cls: 0.03483  loss_box_reg: 0.07207  loss_mask: 0.1271  loss_rpn_cls: 7.014e-05  loss_rpn_loc: 0.006703  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 11:02:02 d2.utils.events]: \u001b[0m eta: 5:57:50  iter: 2039  total_loss: 0.2196  loss_cls: 0.027  loss_box_reg: 0.05514  loss_mask: 0.1198  loss_rpn_cls: 5.857e-05  loss_rpn_loc: 0.00807  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 11:02:26 d2.utils.events]: \u001b[0m eta: 5:49:43  iter: 2059  total_loss: 0.2497  loss_cls: 0.03946  loss_box_reg: 0.07112  loss_mask: 0.1336  loss_rpn_cls: 4.024e-05  loss_rpn_loc: 0.007291  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 11:02:49 d2.utils.events]: \u001b[0m eta: 5:51:07  iter: 2079  total_loss: 0.2613  loss_cls: 0.0389  loss_box_reg: 0.08244  loss_mask: 0.1277  loss_rpn_cls: 7.556e-05  loss_rpn_loc: 0.006497  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 11:03:14 d2.utils.events]: \u001b[0m eta: 6:09:38  iter: 2099  total_loss: 0.1987  loss_cls: 0.02735  loss_box_reg: 0.05665  loss_mask: 0.118  loss_rpn_cls: 2.657e-05  loss_rpn_loc: 0.007271  lr: 0.00025  max_mem: 6288M\n",
            "Loss has not improved for 100 iterations\n",
            "\u001b[32m[07/31 11:03:38 d2.utils.events]: \u001b[0m eta: 5:58:55  iter: 2119  total_loss: 0.2469  loss_cls: 0.03201  loss_box_reg: 0.0721  loss_mask: 0.128  loss_rpn_cls: 1.901e-05  loss_rpn_loc: 0.007264  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 11:04:02 d2.utils.events]: \u001b[0m eta: 5:50:12  iter: 2139  total_loss: 0.2779  loss_cls: 0.04002  loss_box_reg: 0.08647  loss_mask: 0.1377  loss_rpn_cls: 1.008e-05  loss_rpn_loc: 0.006917  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 11:04:26 d2.utils.events]: \u001b[0m eta: 6:08:38  iter: 2159  total_loss: 0.212  loss_cls: 0.03206  loss_box_reg: 0.06917  loss_mask: 0.1112  loss_rpn_cls: 2.829e-05  loss_rpn_loc: 0.005575  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 11:04:51 d2.utils.events]: \u001b[0m eta: 6:01:25  iter: 2179  total_loss: 0.236  loss_cls: 0.0317  loss_box_reg: 0.06143  loss_mask: 0.1367  loss_rpn_cls: 6.773e-05  loss_rpn_loc: 0.006319  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 11:05:15 d2.utils.events]: \u001b[0m eta: 5:59:36  iter: 2199  total_loss: 0.2141  loss_cls: 0.02567  loss_box_reg: 0.05693  loss_mask: 0.1222  loss_rpn_cls: 6.219e-06  loss_rpn_loc: 0.004787  lr: 0.00025  max_mem: 6288M\n",
            "Loss has not improved for 200 iterations\n",
            "\u001b[32m[07/31 11:05:40 d2.utils.events]: \u001b[0m eta: 6:15:01  iter: 2219  total_loss: 0.2247  loss_cls: 0.03557  loss_box_reg: 0.07409  loss_mask: 0.1113  loss_rpn_cls: 5.11e-05  loss_rpn_loc: 0.005928  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 11:06:04 d2.utils.events]: \u001b[0m eta: 5:51:16  iter: 2239  total_loss: 0.2405  loss_cls: 0.03635  loss_box_reg: 0.05773  loss_mask: 0.1221  loss_rpn_cls: 2.531e-05  loss_rpn_loc: 0.00636  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 11:06:27 d2.utils.events]: \u001b[0m eta: 5:35:38  iter: 2259  total_loss: 0.2006  loss_cls: 0.02496  loss_box_reg: 0.05993  loss_mask: 0.1192  loss_rpn_cls: 3.487e-05  loss_rpn_loc: 0.007122  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 11:06:52 d2.utils.events]: \u001b[0m eta: 6:18:27  iter: 2279  total_loss: 0.2343  loss_cls: 0.02791  loss_box_reg: 0.05794  loss_mask: 0.1336  loss_rpn_cls: 2.892e-05  loss_rpn_loc: 0.006119  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 11:07:15 d2.utils.events]: \u001b[0m eta: 5:33:49  iter: 2299  total_loss: 0.2179  loss_cls: 0.03016  loss_box_reg: 0.06108  loss_mask: 0.1191  loss_rpn_cls: 5.432e-05  loss_rpn_loc: 0.005638  lr: 0.00025  max_mem: 6288M\n",
            "Loss has not improved for 300 iterations\n",
            "\u001b[32m[07/31 11:07:39 d2.utils.events]: \u001b[0m eta: 5:55:50  iter: 2319  total_loss: 0.2086  loss_cls: 0.03096  loss_box_reg: 0.06034  loss_mask: 0.1107  loss_rpn_cls: 2.082e-05  loss_rpn_loc: 0.005283  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 11:08:06 d2.utils.events]: \u001b[0m eta: 6:30:13  iter: 2339  total_loss: 0.2061  loss_cls: 0.03153  loss_box_reg: 0.06648  loss_mask: 0.1087  loss_rpn_cls: 2.729e-05  loss_rpn_loc: 0.005712  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 11:08:30 d2.utils.events]: \u001b[0m eta: 6:02:36  iter: 2359  total_loss: 0.2333  loss_cls: 0.03411  loss_box_reg: 0.06664  loss_mask: 0.1352  loss_rpn_cls: 2.068e-05  loss_rpn_loc: 0.005539  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 11:08:56 d2.utils.events]: \u001b[0m eta: 6:22:30  iter: 2379  total_loss: 0.2267  loss_cls: 0.028  loss_box_reg: 0.06387  loss_mask: 0.1203  loss_rpn_cls: 2.566e-05  loss_rpn_loc: 0.007267  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 11:09:22 d2.utils.events]: \u001b[0m eta: 6:12:49  iter: 2399  total_loss: 0.1901  loss_cls: 0.02737  loss_box_reg: 0.05428  loss_mask: 0.1071  loss_rpn_cls: 0.0001019  loss_rpn_loc: 0.004946  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 11:09:45 d2.utils.events]: \u001b[0m eta: 5:38:26  iter: 2419  total_loss: 0.207  loss_cls: 0.02852  loss_box_reg: 0.06114  loss_mask: 0.1075  loss_rpn_cls: 8.771e-05  loss_rpn_loc: 0.005817  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 11:10:09 d2.utils.events]: \u001b[0m eta: 5:44:28  iter: 2439  total_loss: 0.2453  loss_cls: 0.03614  loss_box_reg: 0.07771  loss_mask: 0.1219  loss_rpn_cls: 3.146e-05  loss_rpn_loc: 0.005753  lr: 0.00025  max_mem: 6288M\n",
            "\u001b[32m[07/31 11:10:31 d2.utils.events]: \u001b[0m eta: 5:31:37  iter: 2459  total_loss: 0.1902  loss_cls: 0.02411  loss_box_reg: 0.04822  loss_mask: 0.1162  loss_rpn_cls: 1.322e-05  loss_rpn_loc: 0.004245  lr: 0.00025  max_mem: 6329M\n",
            "Loss has not improved for 100 iterations\n",
            "\u001b[32m[07/31 11:10:57 d2.utils.events]: \u001b[0m eta: 6:18:32  iter: 2479  total_loss: 0.2135  loss_cls: 0.03039  loss_box_reg: 0.06727  loss_mask: 0.1069  loss_rpn_cls: 2.813e-05  loss_rpn_loc: 0.006356  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:11:20 d2.utils.events]: \u001b[0m eta: 5:38:56  iter: 2499  total_loss: 0.2051  loss_cls: 0.0261  loss_box_reg: 0.05945  loss_mask: 0.1138  loss_rpn_cls: 3.892e-05  loss_rpn_loc: 0.005983  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:11:45 d2.utils.events]: \u001b[0m eta: 5:57:31  iter: 2519  total_loss: 0.2131  loss_cls: 0.02526  loss_box_reg: 0.05998  loss_mask: 0.1234  loss_rpn_cls: 2.133e-05  loss_rpn_loc: 0.005044  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:12:10 d2.utils.events]: \u001b[0m eta: 6:03:31  iter: 2539  total_loss: 0.1919  loss_cls: 0.02671  loss_box_reg: 0.05568  loss_mask: 0.1009  loss_rpn_cls: 7.125e-06  loss_rpn_loc: 0.00418  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:12:35 d2.utils.events]: \u001b[0m eta: 6:06:41  iter: 2559  total_loss: 0.206  loss_cls: 0.02835  loss_box_reg: 0.06277  loss_mask: 0.1101  loss_rpn_cls: 0.0001039  loss_rpn_loc: 0.007155  lr: 0.00025  max_mem: 6329M\n",
            "Loss has not improved for 200 iterations\n",
            "\u001b[32m[07/31 11:13:00 d2.utils.events]: \u001b[0m eta: 6:03:47  iter: 2579  total_loss: 0.1928  loss_cls: 0.02793  loss_box_reg: 0.04898  loss_mask: 0.1057  loss_rpn_cls: 3.008e-05  loss_rpn_loc: 0.005575  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:13:25 d2.utils.events]: \u001b[0m eta: 5:54:05  iter: 2599  total_loss: 0.1978  loss_cls: 0.02244  loss_box_reg: 0.04157  loss_mask: 0.1141  loss_rpn_cls: 3.325e-05  loss_rpn_loc: 0.005092  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:13:49 d2.utils.events]: \u001b[0m eta: 5:46:21  iter: 2619  total_loss: 0.2195  loss_cls: 0.03469  loss_box_reg: 0.06443  loss_mask: 0.113  loss_rpn_cls: 2.45e-05  loss_rpn_loc: 0.006578  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:14:13 d2.utils.events]: \u001b[0m eta: 5:51:28  iter: 2639  total_loss: 0.2006  loss_cls: 0.02182  loss_box_reg: 0.05561  loss_mask: 0.1092  loss_rpn_cls: 7.403e-05  loss_rpn_loc: 0.005399  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:14:36 d2.utils.events]: \u001b[0m eta: 5:37:08  iter: 2659  total_loss: 0.2076  loss_cls: 0.02714  loss_box_reg: 0.04742  loss_mask: 0.1117  loss_rpn_cls: 2.353e-05  loss_rpn_loc: 0.00513  lr: 0.00025  max_mem: 6329M\n",
            "Loss has not improved for 300 iterations\n",
            "\u001b[32m[07/31 11:15:00 d2.utils.events]: \u001b[0m eta: 5:47:35  iter: 2679  total_loss: 0.2293  loss_cls: 0.03017  loss_box_reg: 0.06643  loss_mask: 0.1239  loss_rpn_cls: 4.554e-05  loss_rpn_loc: 0.005473  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:15:26 d2.utils.events]: \u001b[0m eta: 6:08:19  iter: 2699  total_loss: 0.1788  loss_cls: 0.0271  loss_box_reg: 0.04183  loss_mask: 0.09825  loss_rpn_cls: 2.123e-05  loss_rpn_loc: 0.005935  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:15:49 d2.utils.events]: \u001b[0m eta: 5:32:44  iter: 2719  total_loss: 0.2056  loss_cls: 0.03033  loss_box_reg: 0.06725  loss_mask: 0.1154  loss_rpn_cls: 5.525e-05  loss_rpn_loc: 0.005848  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:16:13 d2.utils.events]: \u001b[0m eta: 5:46:02  iter: 2739  total_loss: 0.1786  loss_cls: 0.02358  loss_box_reg: 0.04261  loss_mask: 0.1133  loss_rpn_cls: 2.481e-05  loss_rpn_loc: 0.006528  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:16:38 d2.utils.events]: \u001b[0m eta: 5:53:15  iter: 2759  total_loss: 0.2014  loss_cls: 0.02719  loss_box_reg: 0.05575  loss_mask: 0.1056  loss_rpn_cls: 1.527e-05  loss_rpn_loc: 0.004918  lr: 0.00025  max_mem: 6329M\n",
            "Loss has not improved for 400 iterations\n",
            "\u001b[32m[07/31 11:17:03 d2.utils.events]: \u001b[0m eta: 6:01:29  iter: 2779  total_loss: 0.2051  loss_cls: 0.02866  loss_box_reg: 0.05603  loss_mask: 0.1099  loss_rpn_cls: 1.901e-05  loss_rpn_loc: 0.00591  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:17:27 d2.utils.events]: \u001b[0m eta: 5:45:41  iter: 2799  total_loss: 0.1836  loss_cls: 0.02332  loss_box_reg: 0.04723  loss_mask: 0.1131  loss_rpn_cls: 8.982e-06  loss_rpn_loc: 0.004181  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:17:53 d2.utils.events]: \u001b[0m eta: 6:12:17  iter: 2819  total_loss: 0.2548  loss_cls: 0.03631  loss_box_reg: 0.07412  loss_mask: 0.1232  loss_rpn_cls: 2.894e-05  loss_rpn_loc: 0.005195  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:18:17 d2.utils.events]: \u001b[0m eta: 5:45:32  iter: 2839  total_loss: 0.1756  loss_cls: 0.02339  loss_box_reg: 0.04411  loss_mask: 0.1002  loss_rpn_cls: 2.821e-05  loss_rpn_loc: 0.004796  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:18:41 d2.utils.events]: \u001b[0m eta: 5:46:30  iter: 2859  total_loss: 0.1815  loss_cls: 0.02325  loss_box_reg: 0.04092  loss_mask: 0.108  loss_rpn_cls: 7.692e-06  loss_rpn_loc: 0.0054  lr: 0.00025  max_mem: 6329M\n",
            "Loss has not improved for 500 iterations\n",
            "\u001b[32m[07/31 11:19:05 d2.utils.events]: \u001b[0m eta: 5:34:08  iter: 2879  total_loss: 0.2002  loss_cls: 0.02743  loss_box_reg: 0.06321  loss_mask: 0.108  loss_rpn_cls: 4.333e-05  loss_rpn_loc: 0.006561  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:19:29 d2.utils.events]: \u001b[0m eta: 5:46:25  iter: 2899  total_loss: 0.1874  loss_cls: 0.02168  loss_box_reg: 0.05471  loss_mask: 0.1  loss_rpn_cls: 3.905e-05  loss_rpn_loc: 0.00621  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:19:54 d2.utils.events]: \u001b[0m eta: 5:48:44  iter: 2919  total_loss: 0.2105  loss_cls: 0.02553  loss_box_reg: 0.06302  loss_mask: 0.1216  loss_rpn_cls: 2.67e-05  loss_rpn_loc: 0.00667  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:20:19 d2.utils.events]: \u001b[0m eta: 5:55:44  iter: 2939  total_loss: 0.1847  loss_cls: 0.02353  loss_box_reg: 0.05558  loss_mask: 0.09763  loss_rpn_cls: 7.205e-06  loss_rpn_loc: 0.004092  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:20:41 d2.utils.events]: \u001b[0m eta: 5:20:15  iter: 2959  total_loss: 0.1855  loss_cls: 0.02003  loss_box_reg: 0.04508  loss_mask: 0.1118  loss_rpn_cls: 1.655e-05  loss_rpn_loc: 0.005843  lr: 0.00025  max_mem: 6329M\n",
            "Loss has not improved for 600 iterations\n",
            "\u001b[32m[07/31 11:21:06 d2.utils.events]: \u001b[0m eta: 5:49:17  iter: 2979  total_loss: 0.19  loss_cls: 0.02411  loss_box_reg: 0.06403  loss_mask: 0.1019  loss_rpn_cls: 2.689e-05  loss_rpn_loc: 0.006575  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:21:31 d2.utils.events]: \u001b[0m eta: 6:01:54  iter: 2999  total_loss: 0.19  loss_cls: 0.02581  loss_box_reg: 0.04877  loss_mask: 0.1029  loss_rpn_cls: 4.181e-05  loss_rpn_loc: 0.005602  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:21:55 d2.utils.events]: \u001b[0m eta: 5:39:36  iter: 3019  total_loss: 0.1749  loss_cls: 0.02396  loss_box_reg: 0.04989  loss_mask: 0.1012  loss_rpn_cls: 9.136e-06  loss_rpn_loc: 0.005937  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:22:19 d2.utils.events]: \u001b[0m eta: 5:32:58  iter: 3039  total_loss: 0.1622  loss_cls: 0.0212  loss_box_reg: 0.03673  loss_mask: 0.1029  loss_rpn_cls: 2.42e-05  loss_rpn_loc: 0.003871  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:22:43 d2.utils.events]: \u001b[0m eta: 5:45:35  iter: 3059  total_loss: 0.1807  loss_cls: 0.02513  loss_box_reg: 0.04557  loss_mask: 0.1101  loss_rpn_cls: 9.441e-06  loss_rpn_loc: 0.005056  lr: 0.00025  max_mem: 6329M\n",
            "Loss has not improved for 700 iterations\n",
            "\u001b[32m[07/31 11:23:09 d2.utils.events]: \u001b[0m eta: 6:06:09  iter: 3079  total_loss: 0.1572  loss_cls: 0.02405  loss_box_reg: 0.03682  loss_mask: 0.1024  loss_rpn_cls: 5.354e-05  loss_rpn_loc: 0.00317  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:23:34 d2.utils.events]: \u001b[0m eta: 5:42:07  iter: 3099  total_loss: 0.2224  loss_cls: 0.02717  loss_box_reg: 0.06591  loss_mask: 0.1187  loss_rpn_cls: 1.883e-05  loss_rpn_loc: 0.005563  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:24:01 d2.utils.events]: \u001b[0m eta: 6:28:08  iter: 3119  total_loss: 0.1539  loss_cls: 0.0218  loss_box_reg: 0.03863  loss_mask: 0.09358  loss_rpn_cls: 1.872e-05  loss_rpn_loc: 0.003815  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:24:25 d2.utils.events]: \u001b[0m eta: 5:36:51  iter: 3139  total_loss: 0.1923  loss_cls: 0.02256  loss_box_reg: 0.04928  loss_mask: 0.103  loss_rpn_cls: 3.895e-05  loss_rpn_loc: 0.005195  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:24:50 d2.utils.events]: \u001b[0m eta: 5:44:10  iter: 3159  total_loss: 0.1695  loss_cls: 0.02762  loss_box_reg: 0.0435  loss_mask: 0.09614  loss_rpn_cls: 1.817e-05  loss_rpn_loc: 0.005506  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:25:13 d2.utils.events]: \u001b[0m eta: 5:32:38  iter: 3179  total_loss: 0.1914  loss_cls: 0.02804  loss_box_reg: 0.05613  loss_mask: 0.1063  loss_rpn_cls: 2.221e-05  loss_rpn_loc: 0.005008  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:25:39 d2.utils.events]: \u001b[0m eta: 6:00:52  iter: 3199  total_loss: 0.1523  loss_cls: 0.01991  loss_box_reg: 0.03654  loss_mask: 0.09143  loss_rpn_cls: 4.289e-05  loss_rpn_loc: 0.006719  lr: 0.00025  max_mem: 6329M\n",
            "Loss has not improved for 100 iterations\n",
            "\u001b[32m[07/31 11:26:02 d2.utils.events]: \u001b[0m eta: 5:21:12  iter: 3219  total_loss: 0.1855  loss_cls: 0.02532  loss_box_reg: 0.05293  loss_mask: 0.09647  loss_rpn_cls: 1.197e-05  loss_rpn_loc: 0.005666  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:26:28 d2.utils.events]: \u001b[0m eta: 6:00:49  iter: 3239  total_loss: 0.1812  loss_cls: 0.02454  loss_box_reg: 0.04881  loss_mask: 0.105  loss_rpn_cls: 5.682e-05  loss_rpn_loc: 0.005181  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:26:51 d2.utils.events]: \u001b[0m eta: 5:26:19  iter: 3259  total_loss: 0.1597  loss_cls: 0.02192  loss_box_reg: 0.04354  loss_mask: 0.0786  loss_rpn_cls: 9.873e-06  loss_rpn_loc: 0.004631  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:27:16 d2.utils.events]: \u001b[0m eta: 5:43:26  iter: 3279  total_loss: 0.2106  loss_cls: 0.02847  loss_box_reg: 0.07885  loss_mask: 0.1165  loss_rpn_cls: 1.751e-05  loss_rpn_loc: 0.00616  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:27:44 d2.utils.events]: \u001b[0m eta: 6:26:55  iter: 3299  total_loss: 0.189  loss_cls: 0.0224  loss_box_reg: 0.05199  loss_mask: 0.1075  loss_rpn_cls: 1.107e-05  loss_rpn_loc: 0.005596  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:28:09 d2.utils.events]: \u001b[0m eta: 5:56:39  iter: 3319  total_loss: 0.1821  loss_cls: 0.02602  loss_box_reg: 0.05459  loss_mask: 0.1035  loss_rpn_cls: 2.473e-05  loss_rpn_loc: 0.005679  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:28:34 d2.utils.events]: \u001b[0m eta: 5:35:03  iter: 3339  total_loss: 0.1809  loss_cls: 0.02275  loss_box_reg: 0.04679  loss_mask: 0.1019  loss_rpn_cls: 8.123e-06  loss_rpn_loc: 0.00433  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:28:58 d2.utils.events]: \u001b[0m eta: 5:38:48  iter: 3359  total_loss: 0.1577  loss_cls: 0.02067  loss_box_reg: 0.03974  loss_mask: 0.09024  loss_rpn_cls: 2.519e-05  loss_rpn_loc: 0.00376  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:29:22 d2.utils.events]: \u001b[0m eta: 5:36:58  iter: 3379  total_loss: 0.1867  loss_cls: 0.02489  loss_box_reg: 0.05146  loss_mask: 0.09615  loss_rpn_cls: 2.095e-05  loss_rpn_loc: 0.004879  lr: 0.00025  max_mem: 6329M\n",
            "Loss has not improved for 100 iterations\n",
            "\u001b[32m[07/31 11:29:46 d2.utils.events]: \u001b[0m eta: 5:31:59  iter: 3399  total_loss: 0.1603  loss_cls: 0.01731  loss_box_reg: 0.05265  loss_mask: 0.101  loss_rpn_cls: 6.276e-05  loss_rpn_loc: 0.004619  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:30:10 d2.utils.events]: \u001b[0m eta: 5:28:24  iter: 3419  total_loss: 0.1462  loss_cls: 0.01758  loss_box_reg: 0.04015  loss_mask: 0.09293  loss_rpn_cls: 1.731e-05  loss_rpn_loc: 0.005253  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:30:35 d2.utils.events]: \u001b[0m eta: 5:46:28  iter: 3439  total_loss: 0.1752  loss_cls: 0.02299  loss_box_reg: 0.04368  loss_mask: 0.1072  loss_rpn_cls: 5.584e-06  loss_rpn_loc: 0.004859  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:31:00 d2.utils.events]: \u001b[0m eta: 5:41:51  iter: 3459  total_loss: 0.1768  loss_cls: 0.02512  loss_box_reg: 0.05912  loss_mask: 0.09363  loss_rpn_cls: 2.264e-05  loss_rpn_loc: 0.005154  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:31:23 d2.utils.events]: \u001b[0m eta: 5:20:10  iter: 3479  total_loss: 0.2343  loss_cls: 0.0307  loss_box_reg: 0.06719  loss_mask: 0.1192  loss_rpn_cls: 3.355e-05  loss_rpn_loc: 0.005848  lr: 0.00025  max_mem: 6329M\n",
            "Loss has not improved for 200 iterations\n",
            "\u001b[32m[07/31 11:31:48 d2.utils.events]: \u001b[0m eta: 5:35:39  iter: 3499  total_loss: 0.1478  loss_cls: 0.02012  loss_box_reg: 0.04489  loss_mask: 0.08139  loss_rpn_cls: 7.783e-06  loss_rpn_loc: 0.004493  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:32:12 d2.utils.events]: \u001b[0m eta: 5:36:29  iter: 3519  total_loss: 0.1689  loss_cls: 0.01991  loss_box_reg: 0.04567  loss_mask: 0.09755  loss_rpn_cls: 1.886e-06  loss_rpn_loc: 0.004306  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:32:36 d2.utils.events]: \u001b[0m eta: 5:25:39  iter: 3539  total_loss: 0.2087  loss_cls: 0.02242  loss_box_reg: 0.06066  loss_mask: 0.1145  loss_rpn_cls: 1.864e-05  loss_rpn_loc: 0.006131  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:33:00 d2.utils.events]: \u001b[0m eta: 5:23:38  iter: 3559  total_loss: 0.1704  loss_cls: 0.01998  loss_box_reg: 0.03904  loss_mask: 0.09435  loss_rpn_cls: 2.479e-05  loss_rpn_loc: 0.004122  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:33:24 d2.utils.events]: \u001b[0m eta: 5:32:57  iter: 3579  total_loss: 0.1821  loss_cls: 0.02351  loss_box_reg: 0.05252  loss_mask: 0.1016  loss_rpn_cls: 1.492e-05  loss_rpn_loc: 0.005538  lr: 0.00025  max_mem: 6329M\n",
            "Loss has not improved for 300 iterations\n",
            "\u001b[32m[07/31 11:33:50 d2.utils.events]: \u001b[0m eta: 5:54:33  iter: 3599  total_loss: 0.1753  loss_cls: 0.02166  loss_box_reg: 0.04745  loss_mask: 0.09793  loss_rpn_cls: 2.103e-05  loss_rpn_loc: 0.004941  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:34:15 d2.utils.events]: \u001b[0m eta: 5:45:53  iter: 3619  total_loss: 0.1839  loss_cls: 0.0254  loss_box_reg: 0.05062  loss_mask: 0.0965  loss_rpn_cls: 9.267e-06  loss_rpn_loc: 0.005968  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:34:39 d2.utils.events]: \u001b[0m eta: 5:28:50  iter: 3639  total_loss: 0.1654  loss_cls: 0.01808  loss_box_reg: 0.04168  loss_mask: 0.1011  loss_rpn_cls: 2.133e-05  loss_rpn_loc: 0.003556  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:35:05 d2.utils.events]: \u001b[0m eta: 5:44:50  iter: 3659  total_loss: 0.1618  loss_cls: 0.01846  loss_box_reg: 0.04643  loss_mask: 0.09052  loss_rpn_cls: 2.795e-05  loss_rpn_loc: 0.004256  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:35:28 d2.utils.events]: \u001b[0m eta: 5:23:53  iter: 3679  total_loss: 0.186  loss_cls: 0.02438  loss_box_reg: 0.0599  loss_mask: 0.1006  loss_rpn_cls: 1.435e-05  loss_rpn_loc: 0.004681  lr: 0.00025  max_mem: 6329M\n",
            "Loss has not improved for 400 iterations\n",
            "\u001b[32m[07/31 11:35:52 d2.utils.events]: \u001b[0m eta: 5:24:54  iter: 3699  total_loss: 0.1569  loss_cls: 0.0193  loss_box_reg: 0.03665  loss_mask: 0.08785  loss_rpn_cls: 9.827e-06  loss_rpn_loc: 0.004644  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:36:17 d2.utils.events]: \u001b[0m eta: 5:36:10  iter: 3719  total_loss: 0.1713  loss_cls: 0.02175  loss_box_reg: 0.05196  loss_mask: 0.0963  loss_rpn_cls: 1.066e-05  loss_rpn_loc: 0.003388  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:36:39 d2.utils.events]: \u001b[0m eta: 5:02:14  iter: 3739  total_loss: 0.1641  loss_cls: 0.02134  loss_box_reg: 0.04345  loss_mask: 0.09876  loss_rpn_cls: 3.788e-05  loss_rpn_loc: 0.004083  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:37:03 d2.utils.events]: \u001b[0m eta: 5:15:13  iter: 3759  total_loss: 0.174  loss_cls: 0.02434  loss_box_reg: 0.04754  loss_mask: 0.09439  loss_rpn_cls: 3.581e-05  loss_rpn_loc: 0.00623  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:37:28 d2.utils.events]: \u001b[0m eta: 5:37:00  iter: 3779  total_loss: 0.2029  loss_cls: 0.02313  loss_box_reg: 0.05966  loss_mask: 0.1058  loss_rpn_cls: 6.666e-06  loss_rpn_loc: 0.005541  lr: 0.00025  max_mem: 6329M\n",
            "Loss has not improved for 500 iterations\n",
            "\u001b[32m[07/31 11:37:56 d2.utils.events]: \u001b[0m eta: 6:16:09  iter: 3799  total_loss: 0.1722  loss_cls: 0.02174  loss_box_reg: 0.04337  loss_mask: 0.09932  loss_rpn_cls: 1.011e-05  loss_rpn_loc: 0.004552  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:38:19 d2.utils.events]: \u001b[0m eta: 5:18:01  iter: 3819  total_loss: 0.1585  loss_cls: 0.02178  loss_box_reg: 0.04808  loss_mask: 0.09019  loss_rpn_cls: 6.897e-06  loss_rpn_loc: 0.004136  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:38:43 d2.utils.events]: \u001b[0m eta: 5:21:57  iter: 3839  total_loss: 0.192  loss_cls: 0.0249  loss_box_reg: 0.06818  loss_mask: 0.09008  loss_rpn_cls: 1.788e-05  loss_rpn_loc: 0.004079  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:39:08 d2.utils.events]: \u001b[0m eta: 5:33:42  iter: 3859  total_loss: 0.1276  loss_cls: 0.01619  loss_box_reg: 0.03346  loss_mask: 0.08019  loss_rpn_cls: 2.536e-05  loss_rpn_loc: 0.004014  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:39:33 d2.utils.events]: \u001b[0m eta: 5:33:59  iter: 3879  total_loss: 0.2055  loss_cls: 0.02936  loss_box_reg: 0.06378  loss_mask: 0.1014  loss_rpn_cls: 1.348e-05  loss_rpn_loc: 0.00447  lr: 0.00025  max_mem: 6329M\n",
            "Loss has not improved for 100 iterations\n",
            "\u001b[32m[07/31 11:39:56 d2.utils.events]: \u001b[0m eta: 5:09:43  iter: 3899  total_loss: 0.1701  loss_cls: 0.01784  loss_box_reg: 0.04426  loss_mask: 0.08945  loss_rpn_cls: 7.795e-06  loss_rpn_loc: 0.003776  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:40:19 d2.utils.events]: \u001b[0m eta: 5:16:55  iter: 3919  total_loss: 0.1827  loss_cls: 0.02407  loss_box_reg: 0.0581  loss_mask: 0.1037  loss_rpn_cls: 2.644e-05  loss_rpn_loc: 0.005566  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:40:43 d2.utils.events]: \u001b[0m eta: 5:12:05  iter: 3939  total_loss: 0.1842  loss_cls: 0.02433  loss_box_reg: 0.05163  loss_mask: 0.09995  loss_rpn_cls: 1.617e-05  loss_rpn_loc: 0.004901  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:41:08 d2.utils.events]: \u001b[0m eta: 5:33:21  iter: 3959  total_loss: 0.1743  loss_cls: 0.02057  loss_box_reg: 0.05059  loss_mask: 0.09698  loss_rpn_cls: 2.578e-05  loss_rpn_loc: 0.005601  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:41:34 d2.utils.events]: \u001b[0m eta: 5:45:08  iter: 3979  total_loss: 0.1804  loss_cls: 0.02175  loss_box_reg: 0.05713  loss_mask: 0.09781  loss_rpn_cls: 0.0001108  loss_rpn_loc: 0.006342  lr: 0.00025  max_mem: 6329M\n",
            "Loss has not improved for 200 iterations\n",
            "\u001b[32m[07/31 11:41:58 d2.utils.events]: \u001b[0m eta: 5:20:40  iter: 3999  total_loss: 0.1375  loss_cls: 0.01586  loss_box_reg: 0.03247  loss_mask: 0.07782  loss_rpn_cls: 1.42e-05  loss_rpn_loc: 0.0039  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:42:22 d2.utils.events]: \u001b[0m eta: 5:24:21  iter: 4019  total_loss: 0.1868  loss_cls: 0.0255  loss_box_reg: 0.0518  loss_mask: 0.09897  loss_rpn_cls: 2.8e-05  loss_rpn_loc: 0.004839  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:42:47 d2.utils.events]: \u001b[0m eta: 5:28:04  iter: 4039  total_loss: 0.1477  loss_cls: 0.01627  loss_box_reg: 0.03622  loss_mask: 0.08003  loss_rpn_cls: 1.206e-05  loss_rpn_loc: 0.004708  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:43:11 d2.utils.events]: \u001b[0m eta: 5:23:23  iter: 4059  total_loss: 0.1635  loss_cls: 0.01826  loss_box_reg: 0.04119  loss_mask: 0.1027  loss_rpn_cls: 2.536e-05  loss_rpn_loc: 0.006228  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:43:34 d2.utils.events]: \u001b[0m eta: 5:10:08  iter: 4079  total_loss: 0.1531  loss_cls: 0.01803  loss_box_reg: 0.03622  loss_mask: 0.09611  loss_rpn_cls: 8.853e-06  loss_rpn_loc: 0.004005  lr: 0.00025  max_mem: 6329M\n",
            "Loss has not improved for 300 iterations\n",
            "\u001b[32m[07/31 11:43:58 d2.utils.events]: \u001b[0m eta: 5:18:00  iter: 4099  total_loss: 0.1461  loss_cls: 0.01591  loss_box_reg: 0.03619  loss_mask: 0.08996  loss_rpn_cls: 2.723e-05  loss_rpn_loc: 0.003996  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:44:21 d2.utils.events]: \u001b[0m eta: 4:55:43  iter: 4119  total_loss: 0.1492  loss_cls: 0.02043  loss_box_reg: 0.03997  loss_mask: 0.0919  loss_rpn_cls: 1.352e-05  loss_rpn_loc: 0.003848  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:44:45 d2.utils.events]: \u001b[0m eta: 5:19:23  iter: 4139  total_loss: 0.1786  loss_cls: 0.02287  loss_box_reg: 0.05364  loss_mask: 0.1014  loss_rpn_cls: 2.431e-05  loss_rpn_loc: 0.004791  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:45:10 d2.utils.events]: \u001b[0m eta: 5:27:47  iter: 4159  total_loss: 0.1654  loss_cls: 0.02579  loss_box_reg: 0.05385  loss_mask: 0.09439  loss_rpn_cls: 3.421e-05  loss_rpn_loc: 0.006041  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:45:34 d2.utils.events]: \u001b[0m eta: 5:22:30  iter: 4179  total_loss: 0.1532  loss_cls: 0.01812  loss_box_reg: 0.03808  loss_mask: 0.08946  loss_rpn_cls: 1.176e-05  loss_rpn_loc: 0.004191  lr: 0.00025  max_mem: 6329M\n",
            "Loss has not improved for 400 iterations\n",
            "\u001b[32m[07/31 11:45:58 d2.utils.events]: \u001b[0m eta: 5:13:56  iter: 4199  total_loss: 0.1568  loss_cls: 0.0203  loss_box_reg: 0.04575  loss_mask: 0.08881  loss_rpn_cls: 2.341e-05  loss_rpn_loc: 0.004655  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:46:22 d2.utils.events]: \u001b[0m eta: 5:08:58  iter: 4219  total_loss: 0.139  loss_cls: 0.01606  loss_box_reg: 0.03453  loss_mask: 0.08561  loss_rpn_cls: 2.108e-05  loss_rpn_loc: 0.003642  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:46:47 d2.utils.events]: \u001b[0m eta: 5:27:58  iter: 4239  total_loss: 0.1889  loss_cls: 0.02894  loss_box_reg: 0.06103  loss_mask: 0.09175  loss_rpn_cls: 3.762e-05  loss_rpn_loc: 0.006961  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:47:10 d2.utils.events]: \u001b[0m eta: 5:03:01  iter: 4259  total_loss: 0.1624  loss_cls: 0.02207  loss_box_reg: 0.04459  loss_mask: 0.09296  loss_rpn_cls: 1.029e-05  loss_rpn_loc: 0.004951  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:47:34 d2.utils.events]: \u001b[0m eta: 5:17:38  iter: 4279  total_loss: 0.1575  loss_cls: 0.02009  loss_box_reg: 0.04573  loss_mask: 0.0873  loss_rpn_cls: 8.546e-06  loss_rpn_loc: 0.004078  lr: 0.00025  max_mem: 6329M\n",
            "Loss has not improved for 500 iterations\n",
            "\u001b[32m[07/31 11:47:58 d2.utils.events]: \u001b[0m eta: 5:15:05  iter: 4299  total_loss: 0.1662  loss_cls: 0.02441  loss_box_reg: 0.0548  loss_mask: 0.09033  loss_rpn_cls: 2.044e-05  loss_rpn_loc: 0.004343  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:48:23 d2.utils.events]: \u001b[0m eta: 5:29:07  iter: 4319  total_loss: 0.1706  loss_cls: 0.01973  loss_box_reg: 0.05248  loss_mask: 0.09768  loss_rpn_cls: 1.465e-05  loss_rpn_loc: 0.005127  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:48:46 d2.utils.events]: \u001b[0m eta: 4:53:57  iter: 4339  total_loss: 0.133  loss_cls: 0.01779  loss_box_reg: 0.02681  loss_mask: 0.08459  loss_rpn_cls: 1.504e-05  loss_rpn_loc: 0.003154  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:49:10 d2.utils.events]: \u001b[0m eta: 5:19:36  iter: 4359  total_loss: 0.1655  loss_cls: 0.0222  loss_box_reg: 0.05155  loss_mask: 0.09146  loss_rpn_cls: 2.563e-05  loss_rpn_loc: 0.006047  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:49:34 d2.utils.events]: \u001b[0m eta: 5:05:28  iter: 4379  total_loss: 0.1452  loss_cls: 0.01607  loss_box_reg: 0.036  loss_mask: 0.08866  loss_rpn_cls: 3.829e-05  loss_rpn_loc: 0.005066  lr: 0.00025  max_mem: 6329M\n",
            "Loss has not improved for 600 iterations\n",
            "\u001b[32m[07/31 11:49:59 d2.utils.events]: \u001b[0m eta: 5:25:15  iter: 4399  total_loss: 0.1551  loss_cls: 0.01536  loss_box_reg: 0.03465  loss_mask: 0.09398  loss_rpn_cls: 4.274e-06  loss_rpn_loc: 0.003922  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:50:24 d2.utils.events]: \u001b[0m eta: 5:32:40  iter: 4419  total_loss: 0.1647  loss_cls: 0.02429  loss_box_reg: 0.05042  loss_mask: 0.09612  loss_rpn_cls: 9.219e-06  loss_rpn_loc: 0.004901  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:50:49 d2.utils.events]: \u001b[0m eta: 5:17:43  iter: 4439  total_loss: 0.1558  loss_cls: 0.01851  loss_box_reg: 0.04184  loss_mask: 0.09349  loss_rpn_cls: 3.243e-05  loss_rpn_loc: 0.005296  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:51:14 d2.utils.events]: \u001b[0m eta: 5:24:23  iter: 4459  total_loss: 0.1758  loss_cls: 0.02344  loss_box_reg: 0.0497  loss_mask: 0.08522  loss_rpn_cls: 1.179e-05  loss_rpn_loc: 0.004597  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:51:40 d2.utils.events]: \u001b[0m eta: 5:34:51  iter: 4479  total_loss: 0.1336  loss_cls: 0.0168  loss_box_reg: 0.03174  loss_mask: 0.08822  loss_rpn_cls: 3.573e-06  loss_rpn_loc: 0.0038  lr: 0.00025  max_mem: 6329M\n",
            "Loss has not improved for 700 iterations\n",
            "\u001b[32m[07/31 11:52:03 d2.utils.events]: \u001b[0m eta: 5:05:29  iter: 4499  total_loss: 0.1812  loss_cls: 0.02632  loss_box_reg: 0.05815  loss_mask: 0.09585  loss_rpn_cls: 2.041e-05  loss_rpn_loc: 0.005275  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:52:27 d2.utils.events]: \u001b[0m eta: 5:00:53  iter: 4519  total_loss: 0.1652  loss_cls: 0.02168  loss_box_reg: 0.04101  loss_mask: 0.08675  loss_rpn_cls: 9.691e-06  loss_rpn_loc: 0.004199  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:52:51 d2.utils.events]: \u001b[0m eta: 5:13:57  iter: 4539  total_loss: 0.1533  loss_cls: 0.02025  loss_box_reg: 0.04222  loss_mask: 0.08851  loss_rpn_cls: 1.338e-05  loss_rpn_loc: 0.003484  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:53:15 d2.utils.events]: \u001b[0m eta: 5:11:29  iter: 4559  total_loss: 0.1421  loss_cls: 0.01833  loss_box_reg: 0.0334  loss_mask: 0.08278  loss_rpn_cls: 3.084e-05  loss_rpn_loc: 0.004209  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:53:38 d2.utils.events]: \u001b[0m eta: 4:57:15  iter: 4579  total_loss: 0.1697  loss_cls: 0.02052  loss_box_reg: 0.0483  loss_mask: 0.09196  loss_rpn_cls: 3.413e-05  loss_rpn_loc: 0.005888  lr: 0.00025  max_mem: 6329M\n",
            "Loss has not improved for 800 iterations\n",
            "\u001b[32m[07/31 11:54:03 d2.utils.events]: \u001b[0m eta: 5:18:04  iter: 4599  total_loss: 0.1473  loss_cls: 0.01578  loss_box_reg: 0.04603  loss_mask: 0.08595  loss_rpn_cls: 3.019e-05  loss_rpn_loc: 0.004774  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:54:28 d2.utils.events]: \u001b[0m eta: 5:16:15  iter: 4619  total_loss: 0.1556  loss_cls: 0.0215  loss_box_reg: 0.04531  loss_mask: 0.08267  loss_rpn_cls: 1.426e-05  loss_rpn_loc: 0.004854  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:54:51 d2.utils.events]: \u001b[0m eta: 4:52:37  iter: 4639  total_loss: 0.1558  loss_cls: 0.02064  loss_box_reg: 0.04726  loss_mask: 0.08435  loss_rpn_cls: 3.378e-05  loss_rpn_loc: 0.004047  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:55:16 d2.utils.events]: \u001b[0m eta: 5:17:49  iter: 4659  total_loss: 0.134  loss_cls: 0.01611  loss_box_reg: 0.04058  loss_mask: 0.0833  loss_rpn_cls: 1.197e-05  loss_rpn_loc: 0.00427  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:55:39 d2.utils.events]: \u001b[0m eta: 5:01:41  iter: 4679  total_loss: 0.1479  loss_cls: 0.01974  loss_box_reg: 0.04216  loss_mask: 0.09059  loss_rpn_cls: 2.4e-05  loss_rpn_loc: 0.004442  lr: 0.00025  max_mem: 6329M\n",
            "Loss has not improved for 900 iterations\n",
            "\u001b[32m[07/31 11:56:04 d2.utils.events]: \u001b[0m eta: 5:10:14  iter: 4699  total_loss: 0.1774  loss_cls: 0.02136  loss_box_reg: 0.05067  loss_mask: 0.09385  loss_rpn_cls: 5.511e-05  loss_rpn_loc: 0.004951  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:56:28 d2.utils.events]: \u001b[0m eta: 5:05:43  iter: 4719  total_loss: 0.1323  loss_cls: 0.01608  loss_box_reg: 0.03497  loss_mask: 0.07671  loss_rpn_cls: 2.489e-05  loss_rpn_loc: 0.003933  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:56:51 d2.utils.events]: \u001b[0m eta: 5:01:24  iter: 4739  total_loss: 0.1753  loss_cls: 0.02333  loss_box_reg: 0.04663  loss_mask: 0.1028  loss_rpn_cls: 1.893e-05  loss_rpn_loc: 0.004833  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:57:16 d2.utils.events]: \u001b[0m eta: 5:13:26  iter: 4759  total_loss: 0.1232  loss_cls: 0.01718  loss_box_reg: 0.0317  loss_mask: 0.06788  loss_rpn_cls: 1.043e-05  loss_rpn_loc: 0.003219  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:57:38 d2.utils.events]: \u001b[0m eta: 4:44:43  iter: 4779  total_loss: 0.1496  loss_cls: 0.01895  loss_box_reg: 0.03953  loss_mask: 0.08882  loss_rpn_cls: 3.011e-05  loss_rpn_loc: 0.005311  lr: 0.00025  max_mem: 6329M\n",
            "Loss has not improved for 1000 iterations\n",
            "\u001b[32m[07/31 11:58:03 d2.utils.events]: \u001b[0m eta: 5:06:29  iter: 4799  total_loss: 0.1614  loss_cls: 0.02015  loss_box_reg: 0.04018  loss_mask: 0.0874  loss_rpn_cls: 8.106e-06  loss_rpn_loc: 0.004267  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:58:27 d2.utils.events]: \u001b[0m eta: 5:08:33  iter: 4819  total_loss: 0.1614  loss_cls: 0.01844  loss_box_reg: 0.04202  loss_mask: 0.1013  loss_rpn_cls: 2.662e-05  loss_rpn_loc: 0.004901  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:58:51 d2.utils.events]: \u001b[0m eta: 5:02:24  iter: 4839  total_loss: 0.1479  loss_cls: 0.01819  loss_box_reg: 0.0396  loss_mask: 0.08121  loss_rpn_cls: 1.128e-05  loss_rpn_loc: 0.004382  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:59:16 d2.utils.events]: \u001b[0m eta: 5:10:42  iter: 4859  total_loss: 0.1184  loss_cls: 0.01559  loss_box_reg: 0.0272  loss_mask: 0.07406  loss_rpn_cls: 1.626e-05  loss_rpn_loc: 0.003453  lr: 0.00025  max_mem: 6329M\n",
            "\u001b[32m[07/31 11:59:40 d2.utils.events]: \u001b[0m eta: 5:02:01  iter: 4879  total_loss: 0.1596  loss_cls: 0.01983  loss_box_reg: 0.03841  loss_mask: 0.09384  loss_rpn_cls: 2.875e-05  loss_rpn_loc: 0.00463  lr: 0.00025  max_mem: 6329M\n",
            "Loss has not improved for 1100 iterations\n",
            "\u001b[32m[07/31 12:00:05 d2.utils.events]: \u001b[0m eta: 5:15:29  iter: 4899  total_loss: 0.1475  loss_cls: 0.01668  loss_box_reg: 0.04308  loss_mask: 0.08538  loss_rpn_cls: 6.862e-06  loss_rpn_loc: 0.004505  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:00:29 d2.utils.events]: \u001b[0m eta: 5:08:18  iter: 4919  total_loss: 0.1678  loss_cls: 0.02013  loss_box_reg: 0.04353  loss_mask: 0.09034  loss_rpn_cls: 1.386e-05  loss_rpn_loc: 0.004795  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:00:52 d2.utils.events]: \u001b[0m eta: 4:52:00  iter: 4939  total_loss: 0.1489  loss_cls: 0.0182  loss_box_reg: 0.03527  loss_mask: 0.08268  loss_rpn_cls: 9.872e-06  loss_rpn_loc: 0.005278  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:01:17 d2.utils.events]: \u001b[0m eta: 5:06:35  iter: 4959  total_loss: 0.1362  loss_cls: 0.01689  loss_box_reg: 0.03852  loss_mask: 0.08438  loss_rpn_cls: 1.406e-05  loss_rpn_loc: 0.003988  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:01:41 d2.utils.events]: \u001b[0m eta: 5:07:43  iter: 4979  total_loss: 0.1553  loss_cls: 0.01961  loss_box_reg: 0.04342  loss_mask: 0.07735  loss_rpn_cls: 4.684e-06  loss_rpn_loc: 0.003628  lr: 0.00025  max_mem: 6355M\n",
            "Loss has not improved for 1200 iterations\n",
            "\u001b[32m[07/31 12:02:06 d2.utils.events]: \u001b[0m eta: 5:05:37  iter: 4999  total_loss: 0.1635  loss_cls: 0.02308  loss_box_reg: 0.04675  loss_mask: 0.0939  loss_rpn_cls: 9.805e-06  loss_rpn_loc: 0.00475  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:02:34 d2.utils.events]: \u001b[0m eta: 5:49:01  iter: 5019  total_loss: 0.1283  loss_cls: 0.01773  loss_box_reg: 0.03784  loss_mask: 0.07278  loss_rpn_cls: 4.273e-06  loss_rpn_loc: 0.00376  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:02:58 d2.utils.events]: \u001b[0m eta: 5:05:51  iter: 5039  total_loss: 0.1485  loss_cls: 0.01572  loss_box_reg: 0.04628  loss_mask: 0.08475  loss_rpn_cls: 1.014e-05  loss_rpn_loc: 0.004202  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:03:23 d2.utils.events]: \u001b[0m eta: 5:02:56  iter: 5059  total_loss: 0.172  loss_cls: 0.02328  loss_box_reg: 0.04822  loss_mask: 0.09414  loss_rpn_cls: 3.878e-05  loss_rpn_loc: 0.00522  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:03:46 d2.utils.events]: \u001b[0m eta: 4:53:38  iter: 5079  total_loss: 0.1295  loss_cls: 0.01359  loss_box_reg: 0.02704  loss_mask: 0.07931  loss_rpn_cls: 6.911e-06  loss_rpn_loc: 0.003482  lr: 0.00025  max_mem: 6355M\n",
            "Loss has not improved for 1300 iterations\n",
            "\u001b[32m[07/31 12:04:11 d2.utils.events]: \u001b[0m eta: 5:07:28  iter: 5099  total_loss: 0.1507  loss_cls: 0.0203  loss_box_reg: 0.04601  loss_mask: 0.07774  loss_rpn_cls: 1.763e-05  loss_rpn_loc: 0.004748  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:04:35 d2.utils.events]: \u001b[0m eta: 4:51:25  iter: 5119  total_loss: 0.1386  loss_cls: 0.01542  loss_box_reg: 0.03192  loss_mask: 0.08215  loss_rpn_cls: 2.789e-05  loss_rpn_loc: 0.003707  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:04:57 d2.utils.events]: \u001b[0m eta: 4:41:54  iter: 5139  total_loss: 0.1245  loss_cls: 0.01623  loss_box_reg: 0.03128  loss_mask: 0.08269  loss_rpn_cls: 9.576e-06  loss_rpn_loc: 0.004342  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:05:23 d2.utils.events]: \u001b[0m eta: 5:13:31  iter: 5159  total_loss: 0.1508  loss_cls: 0.01985  loss_box_reg: 0.04498  loss_mask: 0.0839  loss_rpn_cls: 1.698e-05  loss_rpn_loc: 0.004163  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:05:47 d2.utils.events]: \u001b[0m eta: 4:56:07  iter: 5179  total_loss: 0.1676  loss_cls: 0.02217  loss_box_reg: 0.04588  loss_mask: 0.09339  loss_rpn_cls: 1.946e-05  loss_rpn_loc: 0.004034  lr: 0.00025  max_mem: 6355M\n",
            "Loss has not improved for 1400 iterations\n",
            "\u001b[32m[07/31 12:06:11 d2.utils.events]: \u001b[0m eta: 5:00:13  iter: 5199  total_loss: 0.1338  loss_cls: 0.01606  loss_box_reg: 0.03644  loss_mask: 0.07927  loss_rpn_cls: 1.665e-05  loss_rpn_loc: 0.003283  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:06:35 d2.utils.events]: \u001b[0m eta: 4:58:35  iter: 5219  total_loss: 0.1338  loss_cls: 0.02103  loss_box_reg: 0.03847  loss_mask: 0.07729  loss_rpn_cls: 1.538e-05  loss_rpn_loc: 0.004575  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:06:59 d2.utils.events]: \u001b[0m eta: 4:53:31  iter: 5239  total_loss: 0.1621  loss_cls: 0.01941  loss_box_reg: 0.0423  loss_mask: 0.0913  loss_rpn_cls: 8.305e-06  loss_rpn_loc: 0.004564  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:07:24 d2.utils.events]: \u001b[0m eta: 5:01:41  iter: 5259  total_loss: 0.1232  loss_cls: 0.01261  loss_box_reg: 0.02912  loss_mask: 0.07304  loss_rpn_cls: 1.312e-05  loss_rpn_loc: 0.00287  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:07:48 d2.utils.events]: \u001b[0m eta: 5:02:14  iter: 5279  total_loss: 0.1602  loss_cls: 0.01756  loss_box_reg: 0.04454  loss_mask: 0.08571  loss_rpn_cls: 4.606e-05  loss_rpn_loc: 0.004987  lr: 0.00025  max_mem: 6355M\n",
            "Loss has not improved for 1500 iterations\n",
            "\u001b[32m[07/31 12:08:11 d2.utils.events]: \u001b[0m eta: 4:43:07  iter: 5299  total_loss: 0.1395  loss_cls: 0.02143  loss_box_reg: 0.0407  loss_mask: 0.07863  loss_rpn_cls: 1.225e-05  loss_rpn_loc: 0.004423  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:08:37 d2.utils.events]: \u001b[0m eta: 5:09:13  iter: 5319  total_loss: 0.1721  loss_cls: 0.02176  loss_box_reg: 0.04359  loss_mask: 0.0957  loss_rpn_cls: 1.222e-05  loss_rpn_loc: 0.006184  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:09:02 d2.utils.events]: \u001b[0m eta: 5:13:11  iter: 5339  total_loss: 0.1234  loss_cls: 0.01637  loss_box_reg: 0.02907  loss_mask: 0.07684  loss_rpn_cls: 6.032e-06  loss_rpn_loc: 0.003123  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:09:26 d2.utils.events]: \u001b[0m eta: 4:51:15  iter: 5359  total_loss: 0.1533  loss_cls: 0.01704  loss_box_reg: 0.04703  loss_mask: 0.08559  loss_rpn_cls: 1.518e-05  loss_rpn_loc: 0.004094  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:09:50 d2.utils.events]: \u001b[0m eta: 4:48:44  iter: 5379  total_loss: 0.1248  loss_cls: 0.01791  loss_box_reg: 0.03736  loss_mask: 0.07148  loss_rpn_cls: 5.934e-06  loss_rpn_loc: 0.002929  lr: 0.00025  max_mem: 6355M\n",
            "Loss has not improved for 1600 iterations\n",
            "\u001b[32m[07/31 12:10:13 d2.utils.events]: \u001b[0m eta: 4:46:21  iter: 5399  total_loss: 0.1499  loss_cls: 0.01955  loss_box_reg: 0.04038  loss_mask: 0.08053  loss_rpn_cls: 1.699e-05  loss_rpn_loc: 0.004941  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:10:38 d2.utils.events]: \u001b[0m eta: 4:58:17  iter: 5419  total_loss: 0.1284  loss_cls: 0.0159  loss_box_reg: 0.03366  loss_mask: 0.07734  loss_rpn_cls: 1.554e-05  loss_rpn_loc: 0.003508  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:11:03 d2.utils.events]: \u001b[0m eta: 4:58:19  iter: 5439  total_loss: 0.1506  loss_cls: 0.02286  loss_box_reg: 0.04488  loss_mask: 0.08237  loss_rpn_cls: 6.425e-05  loss_rpn_loc: 0.004552  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:11:26 d2.utils.events]: \u001b[0m eta: 4:47:55  iter: 5459  total_loss: 0.1298  loss_cls: 0.01772  loss_box_reg: 0.03641  loss_mask: 0.0782  loss_rpn_cls: 6.536e-06  loss_rpn_loc: 0.003046  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:11:49 d2.utils.events]: \u001b[0m eta: 4:39:27  iter: 5479  total_loss: 0.1527  loss_cls: 0.02035  loss_box_reg: 0.04617  loss_mask: 0.07841  loss_rpn_cls: 8.133e-06  loss_rpn_loc: 0.004578  lr: 0.00025  max_mem: 6355M\n",
            "Loss has not improved for 1700 iterations\n",
            "\u001b[32m[07/31 12:12:14 d2.utils.events]: \u001b[0m eta: 4:59:16  iter: 5499  total_loss: 0.1442  loss_cls: 0.01835  loss_box_reg: 0.0424  loss_mask: 0.07635  loss_rpn_cls: 5.653e-06  loss_rpn_loc: 0.003918  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:12:38 d2.utils.events]: \u001b[0m eta: 4:46:20  iter: 5519  total_loss: 0.1233  loss_cls: 0.01719  loss_box_reg: 0.03456  loss_mask: 0.07536  loss_rpn_cls: 4.501e-06  loss_rpn_loc: 0.003126  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:13:02 d2.utils.events]: \u001b[0m eta: 4:51:13  iter: 5539  total_loss: 0.1302  loss_cls: 0.01515  loss_box_reg: 0.02881  loss_mask: 0.08022  loss_rpn_cls: 1.984e-05  loss_rpn_loc: 0.004059  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:13:26 d2.utils.events]: \u001b[0m eta: 4:48:52  iter: 5559  total_loss: 0.1432  loss_cls: 0.01463  loss_box_reg: 0.03881  loss_mask: 0.08075  loss_rpn_cls: 9.366e-06  loss_rpn_loc: 0.003524  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:13:49 d2.utils.events]: \u001b[0m eta: 4:39:33  iter: 5579  total_loss: 0.1392  loss_cls: 0.02116  loss_box_reg: 0.04712  loss_mask: 0.07874  loss_rpn_cls: 5.312e-06  loss_rpn_loc: 0.005147  lr: 0.00025  max_mem: 6355M\n",
            "Loss has not improved for 1800 iterations\n",
            "\u001b[32m[07/31 12:14:16 d2.utils.events]: \u001b[0m eta: 5:12:56  iter: 5599  total_loss: 0.1166  loss_cls: 0.01332  loss_box_reg: 0.02477  loss_mask: 0.06987  loss_rpn_cls: 3.076e-05  loss_rpn_loc: 0.003545  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:14:39 d2.utils.events]: \u001b[0m eta: 4:38:44  iter: 5619  total_loss: 0.1452  loss_cls: 0.02068  loss_box_reg: 0.03757  loss_mask: 0.08265  loss_rpn_cls: 3.035e-05  loss_rpn_loc: 0.003602  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:15:03 d2.utils.events]: \u001b[0m eta: 4:49:41  iter: 5639  total_loss: 0.169  loss_cls: 0.01953  loss_box_reg: 0.04922  loss_mask: 0.09333  loss_rpn_cls: 2.882e-05  loss_rpn_loc: 0.004973  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:15:30 d2.utils.events]: \u001b[0m eta: 5:17:12  iter: 5659  total_loss: 0.1353  loss_cls: 0.01575  loss_box_reg: 0.03807  loss_mask: 0.07664  loss_rpn_cls: 7.007e-06  loss_rpn_loc: 0.003719  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:15:53 d2.utils.events]: \u001b[0m eta: 4:42:40  iter: 5679  total_loss: 0.1301  loss_cls: 0.01982  loss_box_reg: 0.03491  loss_mask: 0.07393  loss_rpn_cls: 1.203e-05  loss_rpn_loc: 0.003538  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:16:18 d2.utils.events]: \u001b[0m eta: 5:00:42  iter: 5699  total_loss: 0.1468  loss_cls: 0.02058  loss_box_reg: 0.0413  loss_mask: 0.07808  loss_rpn_cls: 8.461e-06  loss_rpn_loc: 0.005187  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:16:43 d2.utils.events]: \u001b[0m eta: 4:52:03  iter: 5719  total_loss: 0.1383  loss_cls: 0.01684  loss_box_reg: 0.03419  loss_mask: 0.08378  loss_rpn_cls: 1.447e-05  loss_rpn_loc: 0.003515  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:17:09 d2.utils.events]: \u001b[0m eta: 5:09:38  iter: 5739  total_loss: 0.1312  loss_cls: 0.01698  loss_box_reg: 0.03639  loss_mask: 0.07028  loss_rpn_cls: 1.337e-05  loss_rpn_loc: 0.003278  lr: 0.00025  max_mem: 6355M\n",
            "Loss has not improved for 100 iterations\n",
            "\u001b[32m[07/31 12:17:33 d2.utils.events]: \u001b[0m eta: 4:43:57  iter: 5759  total_loss: 0.1383  loss_cls: 0.01775  loss_box_reg: 0.03913  loss_mask: 0.07739  loss_rpn_cls: 1.34e-05  loss_rpn_loc: 0.004034  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:17:56 d2.utils.events]: \u001b[0m eta: 4:38:11  iter: 5779  total_loss: 0.1379  loss_cls: 0.01761  loss_box_reg: 0.03879  loss_mask: 0.08874  loss_rpn_cls: 6.907e-06  loss_rpn_loc: 0.005285  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:18:19 d2.utils.events]: \u001b[0m eta: 4:30:12  iter: 5799  total_loss: 0.141  loss_cls: 0.01625  loss_box_reg: 0.03948  loss_mask: 0.072  loss_rpn_cls: 1.654e-05  loss_rpn_loc: 0.002588  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:18:43 d2.utils.events]: \u001b[0m eta: 4:36:50  iter: 5819  total_loss: 0.1315  loss_cls: 0.01507  loss_box_reg: 0.03901  loss_mask: 0.07727  loss_rpn_cls: 8.412e-06  loss_rpn_loc: 0.003454  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:19:06 d2.utils.events]: \u001b[0m eta: 4:35:38  iter: 5839  total_loss: 0.1416  loss_cls: 0.0193  loss_box_reg: 0.05004  loss_mask: 0.07761  loss_rpn_cls: 5.507e-06  loss_rpn_loc: 0.003938  lr: 0.00025  max_mem: 6355M\n",
            "Loss has not improved for 200 iterations\n",
            "\u001b[32m[07/31 12:19:30 d2.utils.events]: \u001b[0m eta: 4:46:02  iter: 5859  total_loss: 0.1532  loss_cls: 0.01892  loss_box_reg: 0.04677  loss_mask: 0.07638  loss_rpn_cls: 1.169e-05  loss_rpn_loc: 0.004304  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:19:55 d2.utils.events]: \u001b[0m eta: 4:55:48  iter: 5879  total_loss: 0.1242  loss_cls: 0.01772  loss_box_reg: 0.03066  loss_mask: 0.07334  loss_rpn_cls: 1.786e-05  loss_rpn_loc: 0.00291  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:20:18 d2.utils.events]: \u001b[0m eta: 4:29:14  iter: 5899  total_loss: 0.1472  loss_cls: 0.02217  loss_box_reg: 0.04907  loss_mask: 0.08021  loss_rpn_cls: 8.751e-06  loss_rpn_loc: 0.004659  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:20:43 d2.utils.events]: \u001b[0m eta: 4:53:36  iter: 5919  total_loss: 0.1465  loss_cls: 0.01694  loss_box_reg: 0.04515  loss_mask: 0.08147  loss_rpn_cls: 1.14e-05  loss_rpn_loc: 0.004255  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:21:07 d2.utils.events]: \u001b[0m eta: 4:34:08  iter: 5939  total_loss: 0.1334  loss_cls: 0.01675  loss_box_reg: 0.03428  loss_mask: 0.07645  loss_rpn_cls: 2.307e-06  loss_rpn_loc: 0.003281  lr: 0.00025  max_mem: 6355M\n",
            "Loss has not improved for 300 iterations\n",
            "\u001b[32m[07/31 12:21:29 d2.utils.events]: \u001b[0m eta: 4:21:07  iter: 5959  total_loss: 0.1323  loss_cls: 0.01687  loss_box_reg: 0.03769  loss_mask: 0.08172  loss_rpn_cls: 1.149e-05  loss_rpn_loc: 0.003614  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:21:54 d2.utils.events]: \u001b[0m eta: 4:46:36  iter: 5979  total_loss: 0.1577  loss_cls: 0.02123  loss_box_reg: 0.04804  loss_mask: 0.08107  loss_rpn_cls: 9.091e-06  loss_rpn_loc: 0.004408  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:22:18 d2.utils.events]: \u001b[0m eta: 4:41:37  iter: 5999  total_loss: 0.1446  loss_cls: 0.01823  loss_box_reg: 0.03641  loss_mask: 0.08224  loss_rpn_cls: 6.708e-06  loss_rpn_loc: 0.00401  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:22:43 d2.utils.events]: \u001b[0m eta: 4:50:47  iter: 6019  total_loss: 0.1524  loss_cls: 0.01978  loss_box_reg: 0.04017  loss_mask: 0.07978  loss_rpn_cls: 1.365e-05  loss_rpn_loc: 0.004745  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:23:06 d2.utils.events]: \u001b[0m eta: 4:35:53  iter: 6039  total_loss: 0.1238  loss_cls: 0.01652  loss_box_reg: 0.03702  loss_mask: 0.06865  loss_rpn_cls: 1.015e-05  loss_rpn_loc: 0.002793  lr: 0.00025  max_mem: 6355M\n",
            "Loss has not improved for 400 iterations\n",
            "\u001b[32m[07/31 12:23:30 d2.utils.events]: \u001b[0m eta: 4:28:15  iter: 6059  total_loss: 0.1294  loss_cls: 0.01584  loss_box_reg: 0.03622  loss_mask: 0.07632  loss_rpn_cls: 1.099e-05  loss_rpn_loc: 0.00385  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:23:55 d2.utils.events]: \u001b[0m eta: 4:51:31  iter: 6079  total_loss: 0.1898  loss_cls: 0.0182  loss_box_reg: 0.05827  loss_mask: 0.09235  loss_rpn_cls: 2.652e-05  loss_rpn_loc: 0.005349  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:24:19 d2.utils.events]: \u001b[0m eta: 4:36:09  iter: 6099  total_loss: 0.1354  loss_cls: 0.01685  loss_box_reg: 0.04245  loss_mask: 0.07168  loss_rpn_cls: 1.446e-05  loss_rpn_loc: 0.004231  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:24:43 d2.utils.events]: \u001b[0m eta: 4:45:39  iter: 6119  total_loss: 0.1298  loss_cls: 0.01691  loss_box_reg: 0.03458  loss_mask: 0.07669  loss_rpn_cls: 9.702e-06  loss_rpn_loc: 0.004079  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:25:07 d2.utils.events]: \u001b[0m eta: 4:36:22  iter: 6139  total_loss: 0.1323  loss_cls: 0.01632  loss_box_reg: 0.03556  loss_mask: 0.07933  loss_rpn_cls: 2.136e-06  loss_rpn_loc: 0.003096  lr: 0.00025  max_mem: 6355M\n",
            "Loss has not improved for 500 iterations\n",
            "\u001b[32m[07/31 12:25:31 d2.utils.events]: \u001b[0m eta: 4:36:08  iter: 6159  total_loss: 0.1574  loss_cls: 0.01806  loss_box_reg: 0.04637  loss_mask: 0.08576  loss_rpn_cls: 1.8e-05  loss_rpn_loc: 0.005644  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:25:56 d2.utils.events]: \u001b[0m eta: 4:47:41  iter: 6179  total_loss: 0.1367  loss_cls: 0.02006  loss_box_reg: 0.04335  loss_mask: 0.07962  loss_rpn_cls: 1.045e-05  loss_rpn_loc: 0.004566  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:26:20 d2.utils.events]: \u001b[0m eta: 4:38:56  iter: 6199  total_loss: 0.1446  loss_cls: 0.01545  loss_box_reg: 0.04031  loss_mask: 0.07705  loss_rpn_cls: 4.685e-06  loss_rpn_loc: 0.003735  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:26:45 d2.utils.events]: \u001b[0m eta: 4:44:54  iter: 6219  total_loss: 0.1505  loss_cls: 0.0164  loss_box_reg: 0.03504  loss_mask: 0.08109  loss_rpn_cls: 1.045e-05  loss_rpn_loc: 0.004527  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:27:10 d2.utils.events]: \u001b[0m eta: 4:40:34  iter: 6239  total_loss: 0.1379  loss_cls: 0.01474  loss_box_reg: 0.04261  loss_mask: 0.06924  loss_rpn_cls: 7.007e-06  loss_rpn_loc: 0.003221  lr: 0.00025  max_mem: 6355M\n",
            "Loss has not improved for 600 iterations\n",
            "\u001b[32m[07/31 12:27:34 d2.utils.events]: \u001b[0m eta: 4:34:01  iter: 6259  total_loss: 0.1219  loss_cls: 0.01627  loss_box_reg: 0.03293  loss_mask: 0.07318  loss_rpn_cls: 7.842e-06  loss_rpn_loc: 0.003001  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:27:58 d2.utils.events]: \u001b[0m eta: 4:38:21  iter: 6279  total_loss: 0.1771  loss_cls: 0.02356  loss_box_reg: 0.05747  loss_mask: 0.09169  loss_rpn_cls: 1.194e-05  loss_rpn_loc: 0.004973  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:28:21 d2.utils.events]: \u001b[0m eta: 4:27:54  iter: 6299  total_loss: 0.1188  loss_cls: 0.01524  loss_box_reg: 0.02687  loss_mask: 0.06421  loss_rpn_cls: 8.396e-06  loss_rpn_loc: 0.002773  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:28:46 d2.utils.events]: \u001b[0m eta: 4:43:25  iter: 6319  total_loss: 0.1287  loss_cls: 0.01519  loss_box_reg: 0.03793  loss_mask: 0.07798  loss_rpn_cls: 4.53e-06  loss_rpn_loc: 0.003582  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:29:10 d2.utils.events]: \u001b[0m eta: 4:25:55  iter: 6339  total_loss: 0.1253  loss_cls: 0.0133  loss_box_reg: 0.03294  loss_mask: 0.06843  loss_rpn_cls: 4.785e-06  loss_rpn_loc: 0.004137  lr: 0.00025  max_mem: 6355M\n",
            "Loss has not improved for 700 iterations\n",
            "\u001b[32m[07/31 12:29:33 d2.utils.events]: \u001b[0m eta: 4:29:26  iter: 6359  total_loss: 0.1547  loss_cls: 0.01851  loss_box_reg: 0.04871  loss_mask: 0.07891  loss_rpn_cls: 1.154e-05  loss_rpn_loc: 0.004743  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:29:57 d2.utils.events]: \u001b[0m eta: 4:26:27  iter: 6379  total_loss: 0.129  loss_cls: 0.01567  loss_box_reg: 0.03356  loss_mask: 0.07543  loss_rpn_cls: 2.763e-05  loss_rpn_loc: 0.003482  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:30:21 d2.utils.events]: \u001b[0m eta: 4:29:45  iter: 6399  total_loss: 0.1239  loss_cls: 0.01833  loss_box_reg: 0.03365  loss_mask: 0.07055  loss_rpn_cls: 1.144e-05  loss_rpn_loc: 0.004235  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:30:46 d2.utils.events]: \u001b[0m eta: 4:49:31  iter: 6419  total_loss: 0.1192  loss_cls: 0.01393  loss_box_reg: 0.04131  loss_mask: 0.06382  loss_rpn_cls: 8.096e-06  loss_rpn_loc: 0.003706  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:31:10 d2.utils.events]: \u001b[0m eta: 4:28:42  iter: 6439  total_loss: 0.1254  loss_cls: 0.0144  loss_box_reg: 0.03487  loss_mask: 0.0724  loss_rpn_cls: 2.049e-05  loss_rpn_loc: 0.003972  lr: 0.00025  max_mem: 6355M\n",
            "Loss has not improved for 800 iterations\n",
            "\u001b[32m[07/31 12:31:34 d2.utils.events]: \u001b[0m eta: 4:31:22  iter: 6459  total_loss: 0.1209  loss_cls: 0.01491  loss_box_reg: 0.04056  loss_mask: 0.06455  loss_rpn_cls: 3.148e-06  loss_rpn_loc: 0.003129  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:31:59 d2.utils.events]: \u001b[0m eta: 4:37:14  iter: 6479  total_loss: 0.1598  loss_cls: 0.02389  loss_box_reg: 0.04413  loss_mask: 0.08428  loss_rpn_cls: 1.471e-05  loss_rpn_loc: 0.003898  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:32:25 d2.utils.events]: \u001b[0m eta: 5:01:36  iter: 6499  total_loss: 0.126  loss_cls: 0.01498  loss_box_reg: 0.03281  loss_mask: 0.07697  loss_rpn_cls: 7.964e-06  loss_rpn_loc: 0.003982  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:32:50 d2.utils.events]: \u001b[0m eta: 4:35:08  iter: 6519  total_loss: 0.1122  loss_cls: 0.01518  loss_box_reg: 0.03325  loss_mask: 0.06973  loss_rpn_cls: 3.086e-05  loss_rpn_loc: 0.003996  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:33:14 d2.utils.events]: \u001b[0m eta: 4:27:28  iter: 6539  total_loss: 0.1413  loss_cls: 0.0168  loss_box_reg: 0.037  loss_mask: 0.0815  loss_rpn_cls: 1.642e-05  loss_rpn_loc: 0.004197  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:33:38 d2.utils.events]: \u001b[0m eta: 4:33:42  iter: 6559  total_loss: 0.1221  loss_cls: 0.01823  loss_box_reg: 0.03362  loss_mask: 0.07249  loss_rpn_cls: 1.395e-05  loss_rpn_loc: 0.003541  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:34:04 d2.utils.events]: \u001b[0m eta: 4:47:34  iter: 6579  total_loss: 0.1228  loss_cls: 0.01568  loss_box_reg: 0.03152  loss_mask: 0.0769  loss_rpn_cls: 3.085e-06  loss_rpn_loc: 0.0043  lr: 0.00025  max_mem: 6355M\n",
            "Loss has not improved for 100 iterations\n",
            "\u001b[32m[07/31 12:34:29 d2.utils.events]: \u001b[0m eta: 4:36:32  iter: 6599  total_loss: 0.1333  loss_cls: 0.01914  loss_box_reg: 0.03554  loss_mask: 0.07237  loss_rpn_cls: 5.115e-06  loss_rpn_loc: 0.00249  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:34:53 d2.utils.events]: \u001b[0m eta: 4:32:27  iter: 6619  total_loss: 0.1287  loss_cls: 0.01633  loss_box_reg: 0.04003  loss_mask: 0.07048  loss_rpn_cls: 1.887e-05  loss_rpn_loc: 0.004824  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:35:18 d2.utils.events]: \u001b[0m eta: 4:32:52  iter: 6639  total_loss: 0.1446  loss_cls: 0.01733  loss_box_reg: 0.03708  loss_mask: 0.08058  loss_rpn_cls: 1.097e-05  loss_rpn_loc: 0.004337  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:35:41 d2.utils.events]: \u001b[0m eta: 4:20:25  iter: 6659  total_loss: 0.1412  loss_cls: 0.01892  loss_box_reg: 0.04284  loss_mask: 0.07481  loss_rpn_cls: 1.749e-05  loss_rpn_loc: 0.004218  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:36:06 d2.utils.events]: \u001b[0m eta: 4:32:13  iter: 6679  total_loss: 0.1159  loss_cls: 0.01594  loss_box_reg: 0.02951  loss_mask: 0.06432  loss_rpn_cls: 6.104e-06  loss_rpn_loc: 0.002888  lr: 0.00025  max_mem: 6355M\n",
            "Loss has not improved for 200 iterations\n",
            "\u001b[32m[07/31 12:36:29 d2.utils.events]: \u001b[0m eta: 4:21:26  iter: 6699  total_loss: 0.1246  loss_cls: 0.0131  loss_box_reg: 0.03542  loss_mask: 0.07487  loss_rpn_cls: 8.361e-06  loss_rpn_loc: 0.00347  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:36:53 d2.utils.events]: \u001b[0m eta: 4:21:29  iter: 6719  total_loss: 0.1276  loss_cls: 0.01681  loss_box_reg: 0.03453  loss_mask: 0.07795  loss_rpn_cls: 5.057e-06  loss_rpn_loc: 0.004601  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:37:18 d2.utils.events]: \u001b[0m eta: 4:37:18  iter: 6739  total_loss: 0.1475  loss_cls: 0.01962  loss_box_reg: 0.04077  loss_mask: 0.0845  loss_rpn_cls: 4.136e-06  loss_rpn_loc: 0.003979  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:37:41 d2.utils.events]: \u001b[0m eta: 4:17:24  iter: 6759  total_loss: 0.1363  loss_cls: 0.01443  loss_box_reg: 0.03736  loss_mask: 0.07423  loss_rpn_cls: 1.274e-05  loss_rpn_loc: 0.003317  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:38:05 d2.utils.events]: \u001b[0m eta: 4:25:20  iter: 6779  total_loss: 0.1156  loss_cls: 0.01373  loss_box_reg: 0.03033  loss_mask: 0.06262  loss_rpn_cls: 4.353e-06  loss_rpn_loc: 0.003252  lr: 0.00025  max_mem: 6355M\n",
            "Loss has not improved for 300 iterations\n",
            "\u001b[32m[07/31 12:38:31 d2.utils.events]: \u001b[0m eta: 4:40:30  iter: 6799  total_loss: 0.1452  loss_cls: 0.02075  loss_box_reg: 0.04148  loss_mask: 0.08042  loss_rpn_cls: 1.099e-05  loss_rpn_loc: 0.004677  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:38:55 d2.utils.events]: \u001b[0m eta: 4:30:00  iter: 6819  total_loss: 0.1273  loss_cls: 0.01589  loss_box_reg: 0.03046  loss_mask: 0.07454  loss_rpn_cls: 1.485e-05  loss_rpn_loc: 0.003352  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:39:19 d2.utils.events]: \u001b[0m eta: 4:21:32  iter: 6839  total_loss: 0.1546  loss_cls: 0.01782  loss_box_reg: 0.04508  loss_mask: 0.08719  loss_rpn_cls: 1.001e-05  loss_rpn_loc: 0.004711  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:39:41 d2.utils.events]: \u001b[0m eta: 4:00:30  iter: 6859  total_loss: 0.1205  loss_cls: 0.01513  loss_box_reg: 0.03106  loss_mask: 0.0672  loss_rpn_cls: 2.651e-06  loss_rpn_loc: 0.002755  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:40:05 d2.utils.events]: \u001b[0m eta: 4:22:31  iter: 6879  total_loss: 0.1264  loss_cls: 0.01597  loss_box_reg: 0.03324  loss_mask: 0.07197  loss_rpn_cls: 3.063e-05  loss_rpn_loc: 0.0044  lr: 0.00025  max_mem: 6355M\n",
            "Loss has not improved for 400 iterations\n",
            "\u001b[32m[07/31 12:40:28 d2.utils.events]: \u001b[0m eta: 4:13:27  iter: 6899  total_loss: 0.1216  loss_cls: 0.01697  loss_box_reg: 0.03133  loss_mask: 0.07625  loss_rpn_cls: 1.581e-05  loss_rpn_loc: 0.003638  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:40:53 d2.utils.events]: \u001b[0m eta: 4:24:42  iter: 6919  total_loss: 0.1143  loss_cls: 0.01633  loss_box_reg: 0.02675  loss_mask: 0.07012  loss_rpn_cls: 7.393e-06  loss_rpn_loc: 0.003554  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:41:17 d2.utils.events]: \u001b[0m eta: 4:24:48  iter: 6939  total_loss: 0.1351  loss_cls: 0.01827  loss_box_reg: 0.0412  loss_mask: 0.07632  loss_rpn_cls: 3.946e-06  loss_rpn_loc: 0.004506  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:41:41 d2.utils.events]: \u001b[0m eta: 4:16:41  iter: 6959  total_loss: 0.1414  loss_cls: 0.01877  loss_box_reg: 0.04023  loss_mask: 0.07864  loss_rpn_cls: 9.798e-06  loss_rpn_loc: 0.004784  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:42:05 d2.utils.events]: \u001b[0m eta: 4:27:05  iter: 6979  total_loss: 0.1165  loss_cls: 0.01681  loss_box_reg: 0.03148  loss_mask: 0.06704  loss_rpn_cls: 2.061e-06  loss_rpn_loc: 0.003321  lr: 0.00025  max_mem: 6355M\n",
            "Loss has not improved for 500 iterations\n",
            "\u001b[32m[07/31 12:42:31 d2.utils.events]: \u001b[0m eta: 4:37:30  iter: 6999  total_loss: 0.1187  loss_cls: 0.01232  loss_box_reg: 0.03314  loss_mask: 0.07155  loss_rpn_cls: 2.083e-05  loss_rpn_loc: 0.003752  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:42:55 d2.utils.events]: \u001b[0m eta: 4:23:47  iter: 7019  total_loss: 0.1166  loss_cls: 0.01112  loss_box_reg: 0.02407  loss_mask: 0.0729  loss_rpn_cls: 9.576e-06  loss_rpn_loc: 0.002627  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:43:19 d2.utils.events]: \u001b[0m eta: 4:17:54  iter: 7039  total_loss: 0.1411  loss_cls: 0.02052  loss_box_reg: 0.03513  loss_mask: 0.0797  loss_rpn_cls: 1.035e-05  loss_rpn_loc: 0.004001  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:43:44 d2.utils.events]: \u001b[0m eta: 4:26:20  iter: 7059  total_loss: 0.1171  loss_cls: 0.01418  loss_box_reg: 0.03797  loss_mask: 0.06363  loss_rpn_cls: 1.688e-05  loss_rpn_loc: 0.003897  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:44:07 d2.utils.events]: \u001b[0m eta: 4:09:43  iter: 7079  total_loss: 0.1335  loss_cls: 0.01702  loss_box_reg: 0.03517  loss_mask: 0.0783  loss_rpn_cls: 4.073e-06  loss_rpn_loc: 0.003083  lr: 0.00025  max_mem: 6355M\n",
            "Loss has not improved for 600 iterations\n",
            "\u001b[32m[07/31 12:44:32 d2.utils.events]: \u001b[0m eta: 4:27:06  iter: 7099  total_loss: 0.1199  loss_cls: 0.01256  loss_box_reg: 0.02693  loss_mask: 0.07343  loss_rpn_cls: 8.05e-06  loss_rpn_loc: 0.003972  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:44:56 d2.utils.events]: \u001b[0m eta: 4:22:45  iter: 7119  total_loss: 0.1328  loss_cls: 0.01953  loss_box_reg: 0.03668  loss_mask: 0.06766  loss_rpn_cls: 1.422e-05  loss_rpn_loc: 0.003733  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:45:21 d2.utils.events]: \u001b[0m eta: 4:25:01  iter: 7139  total_loss: 0.1468  loss_cls: 0.02267  loss_box_reg: 0.03876  loss_mask: 0.08249  loss_rpn_cls: 7.739e-06  loss_rpn_loc: 0.004295  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:45:44 d2.utils.events]: \u001b[0m eta: 4:07:18  iter: 7159  total_loss: 0.117  loss_cls: 0.0144  loss_box_reg: 0.03097  loss_mask: 0.06423  loss_rpn_cls: 3.743e-06  loss_rpn_loc: 0.002588  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:46:09 d2.utils.events]: \u001b[0m eta: 4:24:42  iter: 7179  total_loss: 0.1264  loss_cls: 0.0163  loss_box_reg: 0.03951  loss_mask: 0.07255  loss_rpn_cls: 1.219e-05  loss_rpn_loc: 0.004311  lr: 0.00025  max_mem: 6355M\n",
            "Loss has not improved for 700 iterations\n",
            "\u001b[32m[07/31 12:46:33 d2.utils.events]: \u001b[0m eta: 4:17:09  iter: 7199  total_loss: 0.1117  loss_cls: 0.01327  loss_box_reg: 0.02817  loss_mask: 0.06973  loss_rpn_cls: 4.224e-06  loss_rpn_loc: 0.002862  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:46:57 d2.utils.events]: \u001b[0m eta: 4:17:34  iter: 7219  total_loss: 0.1405  loss_cls: 0.01668  loss_box_reg: 0.04067  loss_mask: 0.07806  loss_rpn_cls: 9.516e-06  loss_rpn_loc: 0.004214  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:47:22 d2.utils.events]: \u001b[0m eta: 4:20:58  iter: 7239  total_loss: 0.123  loss_cls: 0.01571  loss_box_reg: 0.0332  loss_mask: 0.06787  loss_rpn_cls: 9.151e-06  loss_rpn_loc: 0.003332  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:47:46 d2.utils.events]: \u001b[0m eta: 4:13:10  iter: 7259  total_loss: 0.1342  loss_cls: 0.01782  loss_box_reg: 0.04043  loss_mask: 0.07839  loss_rpn_cls: 7.383e-06  loss_rpn_loc: 0.004008  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:48:11 d2.utils.events]: \u001b[0m eta: 4:26:51  iter: 7279  total_loss: 0.1505  loss_cls: 0.01926  loss_box_reg: 0.0465  loss_mask: 0.07918  loss_rpn_cls: 7.827e-06  loss_rpn_loc: 0.004953  lr: 0.00025  max_mem: 6355M\n",
            "Loss has not improved for 800 iterations\n",
            "\u001b[32m[07/31 12:48:35 d2.utils.events]: \u001b[0m eta: 4:20:25  iter: 7299  total_loss: 0.1398  loss_cls: 0.01633  loss_box_reg: 0.04017  loss_mask: 0.07922  loss_rpn_cls: 3.1e-06  loss_rpn_loc: 0.003817  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:49:00 d2.utils.events]: \u001b[0m eta: 4:24:17  iter: 7319  total_loss: 0.1104  loss_cls: 0.01599  loss_box_reg: 0.02892  loss_mask: 0.06412  loss_rpn_cls: 9.788e-06  loss_rpn_loc: 0.003881  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:49:25 d2.utils.events]: \u001b[0m eta: 4:16:33  iter: 7339  total_loss: 0.1331  loss_cls: 0.01748  loss_box_reg: 0.03674  loss_mask: 0.07535  loss_rpn_cls: 1.103e-05  loss_rpn_loc: 0.004241  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:49:49 d2.utils.events]: \u001b[0m eta: 4:12:52  iter: 7359  total_loss: 0.1132  loss_cls: 0.01318  loss_box_reg: 0.0293  loss_mask: 0.07187  loss_rpn_cls: 3.041e-05  loss_rpn_loc: 0.002478  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:50:12 d2.utils.events]: \u001b[0m eta: 4:01:02  iter: 7379  total_loss: 0.124  loss_cls: 0.0143  loss_box_reg: 0.03358  loss_mask: 0.06776  loss_rpn_cls: 3.445e-05  loss_rpn_loc: 0.004397  lr: 0.00025  max_mem: 6355M\n",
            "Loss has not improved for 900 iterations\n",
            "\u001b[32m[07/31 12:50:36 d2.utils.events]: \u001b[0m eta: 4:15:32  iter: 7399  total_loss: 0.1386  loss_cls: 0.01741  loss_box_reg: 0.04485  loss_mask: 0.07704  loss_rpn_cls: 1.62e-05  loss_rpn_loc: 0.003648  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:51:00 d2.utils.events]: \u001b[0m eta: 4:10:43  iter: 7419  total_loss: 0.1328  loss_cls: 0.01704  loss_box_reg: 0.04205  loss_mask: 0.07644  loss_rpn_cls: 2.385e-06  loss_rpn_loc: 0.003289  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:51:24 d2.utils.events]: \u001b[0m eta: 4:15:55  iter: 7439  total_loss: 0.1257  loss_cls: 0.01505  loss_box_reg: 0.03889  loss_mask: 0.06884  loss_rpn_cls: 6.62e-06  loss_rpn_loc: 0.003496  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:51:49 d2.utils.events]: \u001b[0m eta: 4:12:46  iter: 7459  total_loss: 0.1226  loss_cls: 0.01312  loss_box_reg: 0.03685  loss_mask: 0.07504  loss_rpn_cls: 1.807e-05  loss_rpn_loc: 0.003286  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:52:13 d2.utils.events]: \u001b[0m eta: 4:15:51  iter: 7479  total_loss: 0.1585  loss_cls: 0.01713  loss_box_reg: 0.0515  loss_mask: 0.08015  loss_rpn_cls: 8.063e-06  loss_rpn_loc: 0.003638  lr: 0.00025  max_mem: 6355M\n",
            "Loss has not improved for 1000 iterations\n",
            "\u001b[32m[07/31 12:52:37 d2.utils.events]: \u001b[0m eta: 4:11:22  iter: 7499  total_loss: 0.1099  loss_cls: 0.01354  loss_box_reg: 0.02487  loss_mask: 0.06813  loss_rpn_cls: 8.242e-06  loss_rpn_loc: 0.003269  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:53:01 d2.utils.events]: \u001b[0m eta: 4:02:15  iter: 7519  total_loss: 0.1216  loss_cls: 0.01739  loss_box_reg: 0.03864  loss_mask: 0.06946  loss_rpn_cls: 9.539e-06  loss_rpn_loc: 0.004918  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:53:25 d2.utils.events]: \u001b[0m eta: 4:09:05  iter: 7539  total_loss: 0.1278  loss_cls: 0.01879  loss_box_reg: 0.03357  loss_mask: 0.06426  loss_rpn_cls: 6.6e-06  loss_rpn_loc: 0.004025  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:53:53 d2.utils.events]: \u001b[0m eta: 4:53:01  iter: 7559  total_loss: 0.1394  loss_cls: 0.01795  loss_box_reg: 0.04135  loss_mask: 0.0739  loss_rpn_cls: 9.012e-06  loss_rpn_loc: 0.003584  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:54:17 d2.utils.events]: \u001b[0m eta: 4:06:57  iter: 7579  total_loss: 0.1298  loss_cls: 0.01638  loss_box_reg: 0.03877  loss_mask: 0.06871  loss_rpn_cls: 3.332e-05  loss_rpn_loc: 0.003975  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:54:43 d2.utils.events]: \u001b[0m eta: 4:28:49  iter: 7599  total_loss: 0.1179  loss_cls: 0.01408  loss_box_reg: 0.03294  loss_mask: 0.06915  loss_rpn_cls: 2.12e-05  loss_rpn_loc: 0.003664  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:55:07 d2.utils.events]: \u001b[0m eta: 4:06:13  iter: 7619  total_loss: 0.1306  loss_cls: 0.01531  loss_box_reg: 0.0385  loss_mask: 0.07707  loss_rpn_cls: 1.713e-05  loss_rpn_loc: 0.004642  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:55:30 d2.utils.events]: \u001b[0m eta: 4:02:12  iter: 7639  total_loss: 0.13  loss_cls: 0.01797  loss_box_reg: 0.03827  loss_mask: 0.07625  loss_rpn_cls: 5.075e-06  loss_rpn_loc: 0.004543  lr: 0.00025  max_mem: 6355M\n",
            "Loss has not improved for 100 iterations\n",
            "\u001b[32m[07/31 12:55:54 d2.utils.events]: \u001b[0m eta: 4:07:38  iter: 7659  total_loss: 0.1192  loss_cls: 0.01773  loss_box_reg: 0.03519  loss_mask: 0.06298  loss_rpn_cls: 6.594e-06  loss_rpn_loc: 0.003228  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:56:18 d2.utils.events]: \u001b[0m eta: 4:03:08  iter: 7679  total_loss: 0.1292  loss_cls: 0.01359  loss_box_reg: 0.03515  loss_mask: 0.07759  loss_rpn_cls: 6.725e-06  loss_rpn_loc: 0.003651  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:56:43 d2.utils.events]: \u001b[0m eta: 4:20:15  iter: 7699  total_loss: 0.1218  loss_cls: 0.01468  loss_box_reg: 0.03144  loss_mask: 0.07293  loss_rpn_cls: 3.254e-06  loss_rpn_loc: 0.003524  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:57:08 d2.utils.events]: \u001b[0m eta: 4:16:45  iter: 7719  total_loss: 0.1205  loss_cls: 0.01637  loss_box_reg: 0.03819  loss_mask: 0.06445  loss_rpn_cls: 3.818e-06  loss_rpn_loc: 0.003745  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:57:34 d2.utils.events]: \u001b[0m eta: 4:17:30  iter: 7739  total_loss: 0.1091  loss_cls: 0.01306  loss_box_reg: 0.03059  loss_mask: 0.06308  loss_rpn_cls: 5.403e-06  loss_rpn_loc: 0.002901  lr: 0.00025  max_mem: 6355M\n",
            "Loss has not improved for 200 iterations\n",
            "\u001b[32m[07/31 12:57:58 d2.utils.events]: \u001b[0m eta: 4:07:38  iter: 7759  total_loss: 0.146  loss_cls: 0.01794  loss_box_reg: 0.04522  loss_mask: 0.071  loss_rpn_cls: 4.143e-06  loss_rpn_loc: 0.004841  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:58:23 d2.utils.events]: \u001b[0m eta: 4:13:08  iter: 7779  total_loss: 0.1195  loss_cls: 0.01445  loss_box_reg: 0.02965  loss_mask: 0.07726  loss_rpn_cls: 8.895e-06  loss_rpn_loc: 0.0046  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:58:46 d2.utils.events]: \u001b[0m eta: 3:58:19  iter: 7799  total_loss: 0.1196  loss_cls: 0.01717  loss_box_reg: 0.03137  loss_mask: 0.06412  loss_rpn_cls: 9.615e-06  loss_rpn_loc: 0.003919  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:59:11 d2.utils.events]: \u001b[0m eta: 4:12:52  iter: 7819  total_loss: 0.1353  loss_cls: 0.01501  loss_box_reg: 0.04136  loss_mask: 0.07485  loss_rpn_cls: 4.949e-06  loss_rpn_loc: 0.003759  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 12:59:35 d2.utils.events]: \u001b[0m eta: 4:03:26  iter: 7839  total_loss: 0.1102  loss_cls: 0.01641  loss_box_reg: 0.02931  loss_mask: 0.06468  loss_rpn_cls: 4.487e-06  loss_rpn_loc: 0.003559  lr: 0.00025  max_mem: 6355M\n",
            "Loss has not improved for 300 iterations\n",
            "\u001b[32m[07/31 13:00:01 d2.utils.events]: \u001b[0m eta: 4:17:58  iter: 7859  total_loss: 0.1214  loss_cls: 0.01505  loss_box_reg: 0.03453  loss_mask: 0.0723  loss_rpn_cls: 6.093e-06  loss_rpn_loc: 0.00252  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:00:25 d2.utils.events]: \u001b[0m eta: 4:07:39  iter: 7879  total_loss: 0.1047  loss_cls: 0.01424  loss_box_reg: 0.02724  loss_mask: 0.06304  loss_rpn_cls: 4.776e-06  loss_rpn_loc: 0.003026  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:00:48 d2.utils.events]: \u001b[0m eta: 3:51:07  iter: 7899  total_loss: 0.1213  loss_cls: 0.01375  loss_box_reg: 0.02492  loss_mask: 0.06696  loss_rpn_cls: 2.046e-05  loss_rpn_loc: 0.003248  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:01:13 d2.utils.events]: \u001b[0m eta: 4:11:08  iter: 7919  total_loss: 0.1378  loss_cls: 0.01812  loss_box_reg: 0.04393  loss_mask: 0.07264  loss_rpn_cls: 1.348e-05  loss_rpn_loc: 0.003654  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:01:38 d2.utils.events]: \u001b[0m eta: 4:13:28  iter: 7939  total_loss: 0.1357  loss_cls: 0.01571  loss_box_reg: 0.03955  loss_mask: 0.07699  loss_rpn_cls: 8.73e-06  loss_rpn_loc: 0.003992  lr: 0.00025  max_mem: 6355M\n",
            "Loss has not improved for 400 iterations\n",
            "\u001b[32m[07/31 13:02:02 d2.utils.events]: \u001b[0m eta: 3:58:36  iter: 7959  total_loss: 0.1116  loss_cls: 0.01458  loss_box_reg: 0.03239  loss_mask: 0.06963  loss_rpn_cls: 4.294e-06  loss_rpn_loc: 0.003825  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:02:25 d2.utils.events]: \u001b[0m eta: 3:55:37  iter: 7979  total_loss: 0.1142  loss_cls: 0.01506  loss_box_reg: 0.0357  loss_mask: 0.06757  loss_rpn_cls: 4.302e-05  loss_rpn_loc: 0.003858  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:02:51 d2.utils.events]: \u001b[0m eta: 4:11:48  iter: 7999  total_loss: 0.1301  loss_cls: 0.01816  loss_box_reg: 0.03705  loss_mask: 0.07292  loss_rpn_cls: 7.51e-06  loss_rpn_loc: 0.004075  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:03:15 d2.utils.events]: \u001b[0m eta: 4:06:35  iter: 8019  total_loss: 0.1172  loss_cls: 0.01419  loss_box_reg: 0.03651  loss_mask: 0.06986  loss_rpn_cls: 1.581e-05  loss_rpn_loc: 0.003216  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:03:39 d2.utils.events]: \u001b[0m eta: 3:58:31  iter: 8039  total_loss: 0.1327  loss_cls: 0.01784  loss_box_reg: 0.03217  loss_mask: 0.07453  loss_rpn_cls: 7.904e-06  loss_rpn_loc: 0.004121  lr: 0.00025  max_mem: 6355M\n",
            "Loss has not improved for 500 iterations\n",
            "\u001b[32m[07/31 13:04:04 d2.utils.events]: \u001b[0m eta: 4:04:46  iter: 8059  total_loss: 0.115  loss_cls: 0.01596  loss_box_reg: 0.03077  loss_mask: 0.06668  loss_rpn_cls: 2.653e-06  loss_rpn_loc: 0.003765  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:04:29 d2.utils.events]: \u001b[0m eta: 4:09:51  iter: 8079  total_loss: 0.112  loss_cls: 0.01409  loss_box_reg: 0.03175  loss_mask: 0.06635  loss_rpn_cls: 5.638e-06  loss_rpn_loc: 0.002568  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:04:54 d2.utils.events]: \u001b[0m eta: 4:08:16  iter: 8099  total_loss: 0.1175  loss_cls: 0.01443  loss_box_reg: 0.03014  loss_mask: 0.0707  loss_rpn_cls: 7.618e-06  loss_rpn_loc: 0.003429  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:05:19 d2.utils.events]: \u001b[0m eta: 4:04:59  iter: 8119  total_loss: 0.1016  loss_cls: 0.01256  loss_box_reg: 0.0276  loss_mask: 0.06034  loss_rpn_cls: 1.376e-05  loss_rpn_loc: 0.003256  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:05:44 d2.utils.events]: \u001b[0m eta: 4:06:36  iter: 8139  total_loss: 0.1491  loss_cls: 0.02034  loss_box_reg: 0.0453  loss_mask: 0.08005  loss_rpn_cls: 1.994e-05  loss_rpn_loc: 0.00451  lr: 0.00025  max_mem: 6355M\n",
            "Loss has not improved for 600 iterations\n",
            "\u001b[32m[07/31 13:06:08 d2.utils.events]: \u001b[0m eta: 3:56:20  iter: 8159  total_loss: 0.13  loss_cls: 0.01657  loss_box_reg: 0.03819  loss_mask: 0.07176  loss_rpn_cls: 8.102e-06  loss_rpn_loc: 0.003282  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:06:32 d2.utils.events]: \u001b[0m eta: 3:59:39  iter: 8179  total_loss: 0.1203  loss_cls: 0.01348  loss_box_reg: 0.02787  loss_mask: 0.06599  loss_rpn_cls: 9.034e-06  loss_rpn_loc: 0.003288  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:06:56 d2.utils.events]: \u001b[0m eta: 3:59:20  iter: 8199  total_loss: 0.1302  loss_cls: 0.01502  loss_box_reg: 0.03214  loss_mask: 0.07188  loss_rpn_cls: 1.967e-05  loss_rpn_loc: 0.004656  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:07:20 d2.utils.events]: \u001b[0m eta: 3:52:04  iter: 8219  total_loss: 0.1131  loss_cls: 0.01433  loss_box_reg: 0.02949  loss_mask: 0.07015  loss_rpn_cls: 1.424e-05  loss_rpn_loc: 0.003048  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:07:44 d2.utils.events]: \u001b[0m eta: 3:52:57  iter: 8239  total_loss: 0.1042  loss_cls: 0.0125  loss_box_reg: 0.02732  loss_mask: 0.05972  loss_rpn_cls: 1.795e-05  loss_rpn_loc: 0.002594  lr: 0.00025  max_mem: 6355M\n",
            "Loss has not improved for 700 iterations\n",
            "\u001b[32m[07/31 13:08:08 d2.utils.events]: \u001b[0m eta: 3:54:59  iter: 8259  total_loss: 0.1218  loss_cls: 0.01684  loss_box_reg: 0.03663  loss_mask: 0.06322  loss_rpn_cls: 7.031e-06  loss_rpn_loc: 0.003614  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:08:33 d2.utils.events]: \u001b[0m eta: 4:03:52  iter: 8279  total_loss: 0.1221  loss_cls: 0.0148  loss_box_reg: 0.03611  loss_mask: 0.06378  loss_rpn_cls: 1.435e-05  loss_rpn_loc: 0.003914  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:08:57 d2.utils.events]: \u001b[0m eta: 3:51:36  iter: 8299  total_loss: 0.1229  loss_cls: 0.0151  loss_box_reg: 0.03894  loss_mask: 0.07122  loss_rpn_cls: 1.743e-05  loss_rpn_loc: 0.004321  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:09:22 d2.utils.events]: \u001b[0m eta: 4:04:52  iter: 8319  total_loss: 0.119  loss_cls: 0.01531  loss_box_reg: 0.03272  loss_mask: 0.06433  loss_rpn_cls: 6.041e-06  loss_rpn_loc: 0.003175  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:09:47 d2.utils.events]: \u001b[0m eta: 4:00:58  iter: 8339  total_loss: 0.1155  loss_cls: 0.01352  loss_box_reg: 0.03263  loss_mask: 0.06606  loss_rpn_cls: 5.511e-06  loss_rpn_loc: 0.003008  lr: 0.00025  max_mem: 6355M\n",
            "Loss has not improved for 800 iterations\n",
            "\u001b[32m[07/31 13:10:08 d2.utils.events]: \u001b[0m eta: 3:32:43  iter: 8359  total_loss: 0.09962  loss_cls: 0.0138  loss_box_reg: 0.02869  loss_mask: 0.06557  loss_rpn_cls: 5.05e-06  loss_rpn_loc: 0.00305  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:10:35 d2.utils.events]: \u001b[0m eta: 4:18:07  iter: 8379  total_loss: 0.1189  loss_cls: 0.01726  loss_box_reg: 0.03692  loss_mask: 0.06396  loss_rpn_cls: 2.621e-05  loss_rpn_loc: 0.003493  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:10:59 d2.utils.events]: \u001b[0m eta: 3:47:57  iter: 8399  total_loss: 0.1244  loss_cls: 0.01801  loss_box_reg: 0.03433  loss_mask: 0.06939  loss_rpn_cls: 6.715e-06  loss_rpn_loc: 0.003313  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:11:23 d2.utils.events]: \u001b[0m eta: 3:56:55  iter: 8419  total_loss: 0.1102  loss_cls: 0.01265  loss_box_reg: 0.0283  loss_mask: 0.06123  loss_rpn_cls: 9.057e-06  loss_rpn_loc: 0.003068  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:11:48 d2.utils.events]: \u001b[0m eta: 3:55:07  iter: 8439  total_loss: 0.1146  loss_cls: 0.01597  loss_box_reg: 0.03497  loss_mask: 0.06507  loss_rpn_cls: 7.321e-06  loss_rpn_loc: 0.003025  lr: 0.00025  max_mem: 6355M\n",
            "Loss has not improved for 900 iterations\n",
            "\u001b[32m[07/31 13:12:12 d2.utils.events]: \u001b[0m eta: 3:49:31  iter: 8459  total_loss: 0.1107  loss_cls: 0.01375  loss_box_reg: 0.0291  loss_mask: 0.06768  loss_rpn_cls: 4.603e-06  loss_rpn_loc: 0.002976  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:12:36 d2.utils.events]: \u001b[0m eta: 3:56:41  iter: 8479  total_loss: 0.1104  loss_cls: 0.01604  loss_box_reg: 0.03129  loss_mask: 0.06764  loss_rpn_cls: 4.832e-06  loss_rpn_loc: 0.003444  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:13:01 d2.utils.events]: \u001b[0m eta: 3:55:13  iter: 8499  total_loss: 0.1264  loss_cls: 0.01443  loss_box_reg: 0.03371  loss_mask: 0.06955  loss_rpn_cls: 5.521e-06  loss_rpn_loc: 0.003645  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:13:24 d2.utils.events]: \u001b[0m eta: 3:41:46  iter: 8519  total_loss: 0.1209  loss_cls: 0.01506  loss_box_reg: 0.03444  loss_mask: 0.0679  loss_rpn_cls: 1.971e-05  loss_rpn_loc: 0.004096  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:13:48 d2.utils.events]: \u001b[0m eta: 3:52:50  iter: 8539  total_loss: 0.1153  loss_cls: 0.01485  loss_box_reg: 0.02951  loss_mask: 0.06583  loss_rpn_cls: 1.624e-05  loss_rpn_loc: 0.003368  lr: 0.00025  max_mem: 6355M\n",
            "Loss has not improved for 1000 iterations\n",
            "\u001b[32m[07/31 13:14:13 d2.utils.events]: \u001b[0m eta: 3:58:33  iter: 8559  total_loss: 0.09629  loss_cls: 0.01624  loss_box_reg: 0.0284  loss_mask: 0.05945  loss_rpn_cls: 1.187e-05  loss_rpn_loc: 0.00317  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:14:37 d2.utils.events]: \u001b[0m eta: 3:47:16  iter: 8579  total_loss: 0.1047  loss_cls: 0.01263  loss_box_reg: 0.02789  loss_mask: 0.06921  loss_rpn_cls: 3.754e-06  loss_rpn_loc: 0.002615  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:15:00 d2.utils.events]: \u001b[0m eta: 3:39:34  iter: 8599  total_loss: 0.1187  loss_cls: 0.01774  loss_box_reg: 0.03667  loss_mask: 0.06165  loss_rpn_cls: 7.441e-06  loss_rpn_loc: 0.003935  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:15:24 d2.utils.events]: \u001b[0m eta: 3:41:43  iter: 8619  total_loss: 0.1412  loss_cls: 0.01857  loss_box_reg: 0.04333  loss_mask: 0.06938  loss_rpn_cls: 3.537e-05  loss_rpn_loc: 0.004084  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:15:48 d2.utils.events]: \u001b[0m eta: 3:45:58  iter: 8639  total_loss: 0.11  loss_cls: 0.01291  loss_box_reg: 0.02524  loss_mask: 0.06644  loss_rpn_cls: 1.336e-05  loss_rpn_loc: 0.003149  lr: 0.00025  max_mem: 6355M\n",
            "Loss has not improved for 1100 iterations\n",
            "\u001b[32m[07/31 13:16:12 d2.utils.events]: \u001b[0m eta: 3:55:12  iter: 8659  total_loss: 0.1222  loss_cls: 0.01227  loss_box_reg: 0.03092  loss_mask: 0.06273  loss_rpn_cls: 1.006e-05  loss_rpn_loc: 0.003634  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:16:37 d2.utils.events]: \u001b[0m eta: 3:52:56  iter: 8679  total_loss: 0.1186  loss_cls: 0.0169  loss_box_reg: 0.03067  loss_mask: 0.06943  loss_rpn_cls: 1.444e-05  loss_rpn_loc: 0.003402  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:17:01 d2.utils.events]: \u001b[0m eta: 3:45:49  iter: 8699  total_loss: 0.1071  loss_cls: 0.01395  loss_box_reg: 0.03182  loss_mask: 0.0579  loss_rpn_cls: 6.854e-06  loss_rpn_loc: 0.003057  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:17:25 d2.utils.events]: \u001b[0m eta: 3:41:38  iter: 8719  total_loss: 0.1153  loss_cls: 0.01444  loss_box_reg: 0.02885  loss_mask: 0.06673  loss_rpn_cls: 3.452e-06  loss_rpn_loc: 0.002924  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:17:49 d2.utils.events]: \u001b[0m eta: 3:46:45  iter: 8739  total_loss: 0.126  loss_cls: 0.01916  loss_box_reg: 0.03474  loss_mask: 0.06303  loss_rpn_cls: 5.846e-06  loss_rpn_loc: 0.003009  lr: 0.00025  max_mem: 6355M\n",
            "Loss has not improved for 1200 iterations\n",
            "\u001b[32m[07/31 13:18:12 d2.utils.events]: \u001b[0m eta: 3:38:26  iter: 8759  total_loss: 0.1163  loss_cls: 0.01527  loss_box_reg: 0.03124  loss_mask: 0.06503  loss_rpn_cls: 1.481e-05  loss_rpn_loc: 0.003189  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:18:36 d2.utils.events]: \u001b[0m eta: 3:45:52  iter: 8779  total_loss: 0.111  loss_cls: 0.01356  loss_box_reg: 0.03012  loss_mask: 0.06238  loss_rpn_cls: 6.35e-06  loss_rpn_loc: 0.002859  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:19:00 d2.utils.events]: \u001b[0m eta: 3:40:04  iter: 8799  total_loss: 0.11  loss_cls: 0.01542  loss_box_reg: 0.03014  loss_mask: 0.05932  loss_rpn_cls: 1.042e-05  loss_rpn_loc: 0.003214  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:19:25 d2.utils.events]: \u001b[0m eta: 3:50:06  iter: 8819  total_loss: 0.1097  loss_cls: 0.01452  loss_box_reg: 0.02793  loss_mask: 0.0697  loss_rpn_cls: 7.089e-06  loss_rpn_loc: 0.00283  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:19:48 d2.utils.events]: \u001b[0m eta: 3:38:41  iter: 8839  total_loss: 0.1296  loss_cls: 0.01607  loss_box_reg: 0.03634  loss_mask: 0.07103  loss_rpn_cls: 8.158e-06  loss_rpn_loc: 0.003743  lr: 0.00025  max_mem: 6355M\n",
            "Loss has not improved for 1300 iterations\n",
            "\u001b[32m[07/31 13:20:12 d2.utils.events]: \u001b[0m eta: 3:38:50  iter: 8859  total_loss: 0.09272  loss_cls: 0.009485  loss_box_reg: 0.0244  loss_mask: 0.05602  loss_rpn_cls: 5.74e-06  loss_rpn_loc: 0.002617  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:20:36 d2.utils.events]: \u001b[0m eta: 3:48:02  iter: 8879  total_loss: 0.1436  loss_cls: 0.01992  loss_box_reg: 0.04382  loss_mask: 0.07732  loss_rpn_cls: 1.731e-05  loss_rpn_loc: 0.00548  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:21:01 d2.utils.events]: \u001b[0m eta: 3:48:36  iter: 8899  total_loss: 0.1063  loss_cls: 0.01314  loss_box_reg: 0.02711  loss_mask: 0.05836  loss_rpn_cls: 9.993e-06  loss_rpn_loc: 0.003351  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:21:25 d2.utils.events]: \u001b[0m eta: 3:42:12  iter: 8919  total_loss: 0.1248  loss_cls: 0.01469  loss_box_reg: 0.0392  loss_mask: 0.06508  loss_rpn_cls: 7.195e-06  loss_rpn_loc: 0.00352  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:21:48 d2.utils.events]: \u001b[0m eta: 3:33:24  iter: 8939  total_loss: 0.1138  loss_cls: 0.01383  loss_box_reg: 0.02921  loss_mask: 0.06481  loss_rpn_cls: 8.046e-06  loss_rpn_loc: 0.002891  lr: 0.00025  max_mem: 6355M\n",
            "Loss has not improved for 1400 iterations\n",
            "\u001b[32m[07/31 13:22:14 d2.utils.events]: \u001b[0m eta: 3:53:05  iter: 8959  total_loss: 0.1109  loss_cls: 0.01364  loss_box_reg: 0.03375  loss_mask: 0.07276  loss_rpn_cls: 4.566e-06  loss_rpn_loc: 0.003373  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:22:37 d2.utils.events]: \u001b[0m eta: 3:31:10  iter: 8979  total_loss: 0.121  loss_cls: 0.01731  loss_box_reg: 0.0332  loss_mask: 0.06885  loss_rpn_cls: 9.36e-06  loss_rpn_loc: 0.002992  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:23:00 d2.utils.events]: \u001b[0m eta: 3:36:23  iter: 8999  total_loss: 0.0994  loss_cls: 0.01125  loss_box_reg: 0.02324  loss_mask: 0.06549  loss_rpn_cls: 1.711e-05  loss_rpn_loc: 0.003188  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:23:25 d2.utils.events]: \u001b[0m eta: 3:45:25  iter: 9019  total_loss: 0.09979  loss_cls: 0.01249  loss_box_reg: 0.0258  loss_mask: 0.05621  loss_rpn_cls: 1.2e-05  loss_rpn_loc: 0.002926  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:23:50 d2.utils.events]: \u001b[0m eta: 3:51:28  iter: 9039  total_loss: 0.1339  loss_cls: 0.01659  loss_box_reg: 0.04057  loss_mask: 0.07368  loss_rpn_cls: 6.545e-06  loss_rpn_loc: 0.004059  lr: 0.00025  max_mem: 6355M\n",
            "Loss has not improved for 1500 iterations\n",
            "\u001b[32m[07/31 13:24:14 d2.utils.events]: \u001b[0m eta: 3:39:54  iter: 9059  total_loss: 0.09383  loss_cls: 0.01051  loss_box_reg: 0.02451  loss_mask: 0.05406  loss_rpn_cls: 6.621e-06  loss_rpn_loc: 0.002703  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:24:39 d2.utils.events]: \u001b[0m eta: 3:44:14  iter: 9079  total_loss: 0.1141  loss_cls: 0.0122  loss_box_reg: 0.03377  loss_mask: 0.06692  loss_rpn_cls: 6.368e-06  loss_rpn_loc: 0.004127  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:25:03 d2.utils.events]: \u001b[0m eta: 3:38:45  iter: 9099  total_loss: 0.1161  loss_cls: 0.0155  loss_box_reg: 0.03633  loss_mask: 0.0664  loss_rpn_cls: 1.089e-05  loss_rpn_loc: 0.004205  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:25:26 d2.utils.events]: \u001b[0m eta: 3:25:39  iter: 9119  total_loss: 0.1295  loss_cls: 0.01607  loss_box_reg: 0.04612  loss_mask: 0.06813  loss_rpn_cls: 7.113e-06  loss_rpn_loc: 0.003223  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:25:50 d2.utils.events]: \u001b[0m eta: 3:41:00  iter: 9139  total_loss: 0.1032  loss_cls: 0.01087  loss_box_reg: 0.02821  loss_mask: 0.0629  loss_rpn_cls: 5.417e-06  loss_rpn_loc: 0.003023  lr: 0.00025  max_mem: 6355M\n",
            "Loss has not improved for 1600 iterations\n",
            "\u001b[32m[07/31 13:26:15 d2.utils.events]: \u001b[0m eta: 3:43:24  iter: 9159  total_loss: 0.1175  loss_cls: 0.01541  loss_box_reg: 0.03946  loss_mask: 0.06575  loss_rpn_cls: 2.286e-05  loss_rpn_loc: 0.003305  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:26:39 d2.utils.events]: \u001b[0m eta: 3:35:03  iter: 9179  total_loss: 0.1064  loss_cls: 0.01418  loss_box_reg: 0.03045  loss_mask: 0.06096  loss_rpn_cls: 7.381e-06  loss_rpn_loc: 0.003369  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:27:02 d2.utils.events]: \u001b[0m eta: 3:27:05  iter: 9199  total_loss: 0.1221  loss_cls: 0.01605  loss_box_reg: 0.03351  loss_mask: 0.07548  loss_rpn_cls: 6.216e-06  loss_rpn_loc: 0.003573  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:27:26 d2.utils.events]: \u001b[0m eta: 3:35:42  iter: 9219  total_loss: 0.1348  loss_cls: 0.01753  loss_box_reg: 0.03822  loss_mask: 0.06726  loss_rpn_cls: 1.045e-05  loss_rpn_loc: 0.004422  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:27:51 d2.utils.events]: \u001b[0m eta: 3:45:18  iter: 9239  total_loss: 0.1151  loss_cls: 0.01631  loss_box_reg: 0.03094  loss_mask: 0.06546  loss_rpn_cls: 1.127e-05  loss_rpn_loc: 0.002656  lr: 0.00025  max_mem: 6355M\n",
            "Loss has not improved for 1700 iterations\n",
            "\u001b[32m[07/31 13:28:16 d2.utils.events]: \u001b[0m eta: 3:42:43  iter: 9259  total_loss: 0.1052  loss_cls: 0.0129  loss_box_reg: 0.02383  loss_mask: 0.06108  loss_rpn_cls: 1.4e-05  loss_rpn_loc: 0.003081  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:28:41 d2.utils.events]: \u001b[0m eta: 3:46:12  iter: 9279  total_loss: 0.1328  loss_cls: 0.01443  loss_box_reg: 0.03574  loss_mask: 0.07212  loss_rpn_cls: 1.651e-05  loss_rpn_loc: 0.003224  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:29:05 d2.utils.events]: \u001b[0m eta: 3:32:02  iter: 9299  total_loss: 0.111  loss_cls: 0.01418  loss_box_reg: 0.03363  loss_mask: 0.05961  loss_rpn_cls: 6.317e-06  loss_rpn_loc: 0.002458  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:29:30 d2.utils.events]: \u001b[0m eta: 3:43:57  iter: 9319  total_loss: 0.1149  loss_cls: 0.01163  loss_box_reg: 0.03  loss_mask: 0.0566  loss_rpn_cls: 1.341e-05  loss_rpn_loc: 0.003341  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:29:55 d2.utils.events]: \u001b[0m eta: 3:40:44  iter: 9339  total_loss: 0.1216  loss_cls: 0.01806  loss_box_reg: 0.03407  loss_mask: 0.07054  loss_rpn_cls: 5.134e-06  loss_rpn_loc: 0.003071  lr: 0.00025  max_mem: 6355M\n",
            "Loss has not improved for 1800 iterations\n",
            "\u001b[32m[07/31 13:30:20 d2.utils.events]: \u001b[0m eta: 3:38:54  iter: 9359  total_loss: 0.1176  loss_cls: 0.01825  loss_box_reg: 0.03561  loss_mask: 0.06943  loss_rpn_cls: 1.317e-05  loss_rpn_loc: 0.003135  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:30:45 d2.utils.events]: \u001b[0m eta: 3:44:01  iter: 9379  total_loss: 0.1125  loss_cls: 0.01253  loss_box_reg: 0.03511  loss_mask: 0.05946  loss_rpn_cls: 6.187e-06  loss_rpn_loc: 0.002737  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:31:09 d2.utils.events]: \u001b[0m eta: 3:36:23  iter: 9399  total_loss: 0.1246  loss_cls: 0.01604  loss_box_reg: 0.03564  loss_mask: 0.07416  loss_rpn_cls: 1.176e-05  loss_rpn_loc: 0.003918  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:31:35 d2.utils.events]: \u001b[0m eta: 3:43:20  iter: 9419  total_loss: 0.1049  loss_cls: 0.01549  loss_box_reg: 0.03097  loss_mask: 0.05687  loss_rpn_cls: 6.986e-06  loss_rpn_loc: 0.002951  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:31:58 d2.utils.events]: \u001b[0m eta: 3:24:34  iter: 9439  total_loss: 0.1133  loss_cls: 0.01451  loss_box_reg: 0.02895  loss_mask: 0.066  loss_rpn_cls: 7.519e-06  loss_rpn_loc: 0.002511  lr: 0.00025  max_mem: 6355M\n",
            "Loss has not improved for 1900 iterations\n",
            "\u001b[32m[07/31 13:32:22 d2.utils.events]: \u001b[0m eta: 3:32:05  iter: 9459  total_loss: 0.1106  loss_cls: 0.01438  loss_box_reg: 0.03466  loss_mask: 0.06556  loss_rpn_cls: 6.976e-06  loss_rpn_loc: 0.003393  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:32:47 d2.utils.events]: \u001b[0m eta: 3:34:30  iter: 9479  total_loss: 0.1057  loss_cls: 0.01202  loss_box_reg: 0.02845  loss_mask: 0.06429  loss_rpn_cls: 1.592e-05  loss_rpn_loc: 0.002732  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:33:12 d2.utils.events]: \u001b[0m eta: 3:40:53  iter: 9499  total_loss: 0.1189  loss_cls: 0.01197  loss_box_reg: 0.03223  loss_mask: 0.06231  loss_rpn_cls: 9.563e-06  loss_rpn_loc: 0.003585  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:33:37 d2.utils.events]: \u001b[0m eta: 3:35:49  iter: 9519  total_loss: 0.1051  loss_cls: 0.01194  loss_box_reg: 0.0335  loss_mask: 0.05663  loss_rpn_cls: 2.787e-06  loss_rpn_loc: 0.003858  lr: 0.00025  max_mem: 6355M\n",
            "\u001b[32m[07/31 13:34:00 d2.utils.events]: \u001b[0m eta: 3:21:10  iter: 9539  total_loss: 0.1357  loss_cls: 0.01871  loss_box_reg: 0.04186  loss_mask: 0.07247  loss_rpn_cls: 1.256e-05  loss_rpn_loc: 0.004244  lr: 0.00025  max_mem: 6355M\n",
            "Loss has not improved for 2000 iterations\n",
            "EARLY STOPPING\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/31 13:34:00 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[07/31 13:34:00 d2.data.datasets.coco]: \u001b[0mLoaded 22 images in COCO format from /content/drive/MyDrive/Dataset_v4/test.json\n",
            "\u001b[32m[07/31 13:34:00 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
            "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
            "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
            "| derajat 1  | 9            | derajat 2  | 53           | derajat 3  | 9            |\n",
            "|            |              |            |              |            |              |\n",
            "|   total    | 71           |            |              |            |              |\u001b[0m\n",
            "\u001b[32m[07/31 13:34:00 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[07/31 13:34:00 d2.data.common]: \u001b[0mSerializing 22 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/31 13:34:00 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
            "\u001b[32m[07/31 13:34:00 d2.evaluation.evaluator]: \u001b[0mStart inference on 22 batches\n",
            "\u001b[32m[07/31 13:34:03 d2.evaluation.evaluator]: \u001b[0mInference done 11/22. Dataloading: 0.0013 s/iter. Inference: 0.1494 s/iter. Eval: 0.0055 s/iter. Total: 0.1562 s/iter. ETA=0:00:01\n",
            "\u001b[32m[07/31 13:34:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.944401 (0.232024 s / iter per device, on 1 devices)\n",
            "\u001b[32m[07/31 13:34:06 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.154478 s / iter per device, on 1 devices)\n",
            "\u001b[32m[07/31 13:34:06 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[07/31 13:34:06 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/Test/coco_instances_results.json\n",
            "\u001b[32m[07/31 13:34:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[07/31 13:34:06 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
            "\u001b[32m[07/31 13:34:06 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n",
            "\u001b[32m[07/31 13:34:06 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[07/31 13:34:06 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.559\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.684\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.568\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.177\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.591\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.751\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.307\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.683\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.683\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.350\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.691\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.809\n",
            "\u001b[32m[07/31 13:34:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 55.913 | 68.440 | 56.834 | 17.673 | 59.064 | 75.103 |\n",
            "\u001b[32m[07/31 13:34:06 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP      | category   | AP     | category   | AP     |\n",
            "|:-----------|:--------|:-----------|:-------|:-----------|:-------|\n",
            "| derajat 1  | 100.000 | derajat 2  | 51.152 | derajat 3  | 16.587 |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[07/31 13:34:06 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
            "\u001b[32m[07/31 13:34:06 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.01 seconds.\n",
            "\u001b[32m[07/31 13:34:06 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[07/31 13:34:06 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.536\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.684\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.539\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.058\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.580\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.715\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.297\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.632\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.632\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.250\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.650\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.753\n",
            "\u001b[32m[07/31 13:34:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 53.554 | 68.440 | 53.891 | 5.785 | 58.012 | 71.468 |\n",
            "\u001b[32m[07/31 13:34:06 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| derajat 1  | 97.833 | derajat 2  | 46.088 | derajat 3  | 16.742 |\n",
            "\u001b[32m[07/31 13:34:06 detectron2]: \u001b[0mEvaluation results for Test in csv format:\n",
            "\u001b[32m[07/31 13:34:06 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[07/31 13:34:06 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/31 13:34:06 d2.evaluation.testing]: \u001b[0mcopypaste: 55.9127,68.4395,56.8337,17.6733,59.0643,75.1026\n",
            "\u001b[32m[07/31 13:34:06 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[07/31 13:34:06 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[07/31 13:34:06 d2.evaluation.testing]: \u001b[0mcopypaste: 53.5541,68.4395,53.8915,5.7850,58.0116,71.4678\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "OrderedDict([('bbox',\n",
              "              {'AP': 55.91267217494749,\n",
              "               'AP-derajat 1': 100.0,\n",
              "               'AP-derajat 2': 51.15150073040587,\n",
              "               'AP-derajat 3': 16.586515794436583,\n",
              "               'AP50': 68.43953488551522,\n",
              "               'AP75': 56.833653143586226,\n",
              "               'APl': 75.10262689249167,\n",
              "               'APm': 59.0642783839186,\n",
              "               'APs': 17.673267326732674}),\n",
              "             ('segm',\n",
              "              {'AP': 53.55413902438393,\n",
              "               'AP-derajat 1': 97.83278327832782,\n",
              "               'AP-derajat 2': 46.08792390954971,\n",
              "               'AP-derajat 3': 16.74170988527424,\n",
              "               'AP50': 68.43953488551522,\n",
              "               'AP75': 53.89146222004084,\n",
              "               'APl': 71.46781698208605,\n",
              "               'APm': 58.01156615303265,\n",
              "               'APs': 5.785007072135786})])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def get_evaluator(cfg, dataset_name, output_folder=None):\n",
        "    \"\"\"\n",
        "    Create evaluator(s) for a given dataset.\n",
        "    This uses the special metadata \"evaluator_type\" associated with each builtin dataset.\n",
        "    For your own dataset, you can simply create an evaluator manually in your\n",
        "    script and do not have to worry about the hacky if-else logic here.\n",
        "    \"\"\"\n",
        "    if output_folder is None:\n",
        "        output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\n",
        "    evaluator_list = []\n",
        "    evaluator_type = MetadataCatalog.get(dataset_name).evaluator_type\n",
        "    if evaluator_type in [\"sem_seg\", \"coco_panoptic_seg\"]:\n",
        "        evaluator_list.append(\n",
        "            SemSegEvaluator(\n",
        "                dataset_name,\n",
        "                distributed=True,\n",
        "                output_dir=output_folder,\n",
        "            )\n",
        "        )\n",
        "    if evaluator_type in [\"coco\", \"coco_panoptic_seg\"]:\n",
        "        evaluator_list.append(COCOEvaluator(dataset_name, output_dir=output_folder))\n",
        "    if evaluator_type == \"coco_panoptic_seg\":\n",
        "        evaluator_list.append(COCOPanopticEvaluator(dataset_name, output_folder))\n",
        "    if evaluator_type == \"cityscapes_instance\":\n",
        "        return CityscapesInstanceEvaluator(dataset_name)\n",
        "    if evaluator_type == \"cityscapes_sem_seg\":\n",
        "        return CityscapesSemSegEvaluator(dataset_name)\n",
        "    if evaluator_type == \"pascal_voc\":\n",
        "        return PascalVOCDetectionEvaluator(dataset_name)\n",
        "    if evaluator_type == \"lvis\":\n",
        "        return LVISEvaluator(dataset_name, cfg, True, output_folder)\n",
        "    if len(evaluator_list) == 0:\n",
        "        raise NotImplementedError(\n",
        "            \"no Evaluator for the dataset {} with the type {}\".format(dataset_name, evaluator_type)\n",
        "        )\n",
        "    if len(evaluator_list) == 1:\n",
        "        return evaluator_list[0]\n",
        "    return DatasetEvaluators(evaluator_list)\n",
        "\n",
        "def do_test(cfg, model):\n",
        "    results = OrderedDict()\n",
        "    for dataset_name in cfg.DATASETS.TEST:\n",
        "        data_loader = build_detection_test_loader(cfg, dataset_name)\n",
        "        evaluator = get_evaluator(\n",
        "            cfg, dataset_name, os.path.join(cfg.OUTPUT_DIR, \"inference\", dataset_name)\n",
        "        )\n",
        "        results_i = inference_on_dataset(model, data_loader, evaluator)\n",
        "        results[dataset_name] = results_i\n",
        "        if comm.is_main_process():\n",
        "            logger.info(\"Evaluation results for {} in csv format:\".format(dataset_name))\n",
        "            print_csv_format(results_i)\n",
        "    if len(results) == 1:\n",
        "        results = list(results.values())[0]\n",
        "    return results\n",
        "\n",
        "\n",
        "logger = logging.getLogger(\"detectron2\")\n",
        "resume=False\n",
        "model = build_model(cfg)\n",
        "optimizer = build_optimizer(cfg, model)\n",
        "scheduler = build_lr_scheduler(cfg, optimizer)\n",
        "\n",
        "BEST_LOSS = np.inf\n",
        "\n",
        "checkpointer = DetectionCheckpointer(\n",
        "    model, cfg.OUTPUT_DIR, optimizer=optimizer, scheduler=scheduler\n",
        ")\n",
        "start_iter = (\n",
        "    checkpointer.resume_or_load(cfg.MODEL.WEIGHTS, resume=resume).get(\"iteration\", -1) + 1\n",
        ")\n",
        "prev_iter = start_iter\n",
        "max_iter = cfg.SOLVER.MAX_ITER\n",
        "\n",
        "periodic_checkpointer = PeriodicCheckpointer(\n",
        "    checkpointer, cfg.SOLVER.CHECKPOINT_PERIOD, max_iter=max_iter\n",
        ")\n",
        "\n",
        "writers = default_writers(cfg.OUTPUT_DIR, max_iter) if comm.is_main_process() else []\n",
        "\n",
        "# compared to \"train_net.py\", we do not support accurate timing and\n",
        "# precise BN here, because they are not trivial to implement in a small training loop\n",
        "data_loader = build_detection_train_loader(cfg)\n",
        "logger.info(\"Starting training from iteration {}\".format(start_iter))\n",
        "patience_counter = 0\n",
        "with EventStorage(start_iter) as storage:\n",
        "    for data, iteration in zip(data_loader, range(start_iter, max_iter)):\n",
        "        storage.iter = iteration\n",
        "\n",
        "        loss_dict = model(data)\n",
        "        losses = sum(loss_dict.values())\n",
        "        assert torch.isfinite(losses).all(), loss_dict\n",
        "\n",
        "        loss_dict_reduced = {k: v.item() for k, v in comm.reduce_dict(loss_dict).items()}\n",
        "        losses_reduced = sum(loss for loss in loss_dict_reduced.values())\n",
        "        if comm.is_main_process():\n",
        "            storage.put_scalars(total_loss=losses_reduced, **loss_dict_reduced)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        losses.backward()\n",
        "        optimizer.step()\n",
        "        storage.put_scalar(\"lr\", optimizer.param_groups[0][\"lr\"], smoothing_hint=False)\n",
        "        scheduler.step()\n",
        "\n",
        "        if (\n",
        "            cfg.TEST.EVAL_PERIOD > 0\n",
        "            and (iteration + 1) % cfg.TEST.EVAL_PERIOD == 0\n",
        "            and iteration != max_iter - 1\n",
        "        ):\n",
        "            do_test(cfg, model)\n",
        "            # Compared to \"train_net.py\", the test results are not dumped to EventStorage\n",
        "            comm.synchronize()\n",
        "\n",
        "        if iteration - start_iter > 5 and (\n",
        "            (iteration + 1) % 20 == 0 or iteration == max_iter - 1\n",
        "        ):\n",
        "            for writer in writers:\n",
        "                writer.write()\n",
        "        periodic_checkpointer.step(iteration)\n",
        "        \n",
        "        if iteration > prev_iter:\n",
        "            prev_iter = iteration\n",
        "            if losses_reduced < BEST_LOSS:\n",
        "                BEST_LOSS = losses_reduced\n",
        "                patience_counter = 0\n",
        "                checkpointer.save('best_model')\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "                if patience_counter % 100 == 0:\n",
        "                    print(f\"Loss has not improved for {patience_counter} iterations\")\n",
        "                if patience_counter >= PATIENCE:\n",
        "                    print(f\"EARLY STOPPING\")\n",
        "                    break\n",
        "                \n",
        "do_test(cfg, model)"
      ],
      "id": "043e9caa"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQ-OPoPNJQCA"
      },
      "source": [
        "# Test model and show example output"
      ],
      "id": "cQ-OPoPNJQCA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_UukOsW-TIF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69a41aba-0bce-43d0-cfd0-1ebf608451d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[07/31 13:37:48 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
            "| Names in Model                                  | Names in Checkpoint                                                                                  | Shapes                                          |\n",
            "|:------------------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
            "| backbone.bottom_up.res2.0.conv1.*               | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
            "| backbone.bottom_up.res2.0.conv2.*               | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,8,3,3)         |\n",
            "| backbone.bottom_up.res2.0.conv3.*               | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,1,1)       |\n",
            "| backbone.bottom_up.res2.0.shortcut.*            | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
            "| backbone.bottom_up.res2.1.conv1.*               | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,1,1)       |\n",
            "| backbone.bottom_up.res2.1.conv2.*               | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,8,3,3)         |\n",
            "| backbone.bottom_up.res2.1.conv3.*               | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,1,1)       |\n",
            "| backbone.bottom_up.res2.2.conv1.*               | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,1,1)       |\n",
            "| backbone.bottom_up.res2.2.conv2.*               | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,8,3,3)         |\n",
            "| backbone.bottom_up.res2.2.conv3.*               | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,1,1)       |\n",
            "| backbone.bottom_up.res3.0.conv1.*               | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
            "| backbone.bottom_up.res3.0.conv2.*               | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,16,3,3)        |\n",
            "| backbone.bottom_up.res3.0.conv3.*               | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,1,1)       |\n",
            "| backbone.bottom_up.res3.0.shortcut.*            | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
            "| backbone.bottom_up.res3.1.conv1.*               | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,1,1)       |\n",
            "| backbone.bottom_up.res3.1.conv2.*               | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,16,3,3)        |\n",
            "| backbone.bottom_up.res3.1.conv3.*               | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,1,1)       |\n",
            "| backbone.bottom_up.res3.2.conv1.*               | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,1,1)       |\n",
            "| backbone.bottom_up.res3.2.conv2.*               | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,16,3,3)        |\n",
            "| backbone.bottom_up.res3.2.conv3.*               | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,1,1)       |\n",
            "| backbone.bottom_up.res3.3.conv1.*               | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,1,1)       |\n",
            "| backbone.bottom_up.res3.3.conv2.*               | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,16,3,3)        |\n",
            "| backbone.bottom_up.res3.3.conv3.*               | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,1,1)       |\n",
            "| backbone.bottom_up.res4.0.conv1.*               | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
            "| backbone.bottom_up.res4.0.conv2.*               | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,32,3,3)   |\n",
            "| backbone.bottom_up.res4.0.conv3.*               | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,1024,1,1) |\n",
            "| backbone.bottom_up.res4.0.shortcut.*            | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
            "| backbone.bottom_up.res4.1.conv1.*               | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,1024,1,1) |\n",
            "| backbone.bottom_up.res4.1.conv2.*               | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,32,3,3)   |\n",
            "| backbone.bottom_up.res4.1.conv3.*               | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,1024,1,1) |\n",
            "| backbone.bottom_up.res4.10.conv1.*              | backbone.bottom_up.res4.10.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,1024,1,1) |\n",
            "| backbone.bottom_up.res4.10.conv2.*              | backbone.bottom_up.res4.10.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,32,3,3)   |\n",
            "| backbone.bottom_up.res4.10.conv3.*              | backbone.bottom_up.res4.10.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,1024,1,1) |\n",
            "| backbone.bottom_up.res4.11.conv1.*              | backbone.bottom_up.res4.11.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,1024,1,1) |\n",
            "| backbone.bottom_up.res4.11.conv2.*              | backbone.bottom_up.res4.11.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,32,3,3)   |\n",
            "| backbone.bottom_up.res4.11.conv3.*              | backbone.bottom_up.res4.11.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,1024,1,1) |\n",
            "| backbone.bottom_up.res4.12.conv1.*              | backbone.bottom_up.res4.12.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,1024,1,1) |\n",
            "| backbone.bottom_up.res4.12.conv2.*              | backbone.bottom_up.res4.12.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,32,3,3)   |\n",
            "| backbone.bottom_up.res4.12.conv3.*              | backbone.bottom_up.res4.12.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,1024,1,1) |\n",
            "| backbone.bottom_up.res4.13.conv1.*              | backbone.bottom_up.res4.13.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,1024,1,1) |\n",
            "| backbone.bottom_up.res4.13.conv2.*              | backbone.bottom_up.res4.13.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,32,3,3)   |\n",
            "| backbone.bottom_up.res4.13.conv3.*              | backbone.bottom_up.res4.13.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,1024,1,1) |\n",
            "| backbone.bottom_up.res4.14.conv1.*              | backbone.bottom_up.res4.14.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,1024,1,1) |\n",
            "| backbone.bottom_up.res4.14.conv2.*              | backbone.bottom_up.res4.14.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,32,3,3)   |\n",
            "| backbone.bottom_up.res4.14.conv3.*              | backbone.bottom_up.res4.14.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,1024,1,1) |\n",
            "| backbone.bottom_up.res4.15.conv1.*              | backbone.bottom_up.res4.15.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,1024,1,1) |\n",
            "| backbone.bottom_up.res4.15.conv2.*              | backbone.bottom_up.res4.15.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,32,3,3)   |\n",
            "| backbone.bottom_up.res4.15.conv3.*              | backbone.bottom_up.res4.15.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,1024,1,1) |\n",
            "| backbone.bottom_up.res4.16.conv1.*              | backbone.bottom_up.res4.16.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,1024,1,1) |\n",
            "| backbone.bottom_up.res4.16.conv2.*              | backbone.bottom_up.res4.16.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,32,3,3)   |\n",
            "| backbone.bottom_up.res4.16.conv3.*              | backbone.bottom_up.res4.16.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,1024,1,1) |\n",
            "| backbone.bottom_up.res4.17.conv1.*              | backbone.bottom_up.res4.17.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,1024,1,1) |\n",
            "| backbone.bottom_up.res4.17.conv2.*              | backbone.bottom_up.res4.17.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,32,3,3)   |\n",
            "| backbone.bottom_up.res4.17.conv3.*              | backbone.bottom_up.res4.17.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,1024,1,1) |\n",
            "| backbone.bottom_up.res4.18.conv1.*              | backbone.bottom_up.res4.18.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,1024,1,1) |\n",
            "| backbone.bottom_up.res4.18.conv2.*              | backbone.bottom_up.res4.18.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,32,3,3)   |\n",
            "| backbone.bottom_up.res4.18.conv3.*              | backbone.bottom_up.res4.18.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,1024,1,1) |\n",
            "| backbone.bottom_up.res4.19.conv1.*              | backbone.bottom_up.res4.19.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,1024,1,1) |\n",
            "| backbone.bottom_up.res4.19.conv2.*              | backbone.bottom_up.res4.19.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,32,3,3)   |\n",
            "| backbone.bottom_up.res4.19.conv3.*              | backbone.bottom_up.res4.19.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,1024,1,1) |\n",
            "| backbone.bottom_up.res4.2.conv1.*               | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,1024,1,1) |\n",
            "| backbone.bottom_up.res4.2.conv2.*               | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,32,3,3)   |\n",
            "| backbone.bottom_up.res4.2.conv3.*               | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,1024,1,1) |\n",
            "| backbone.bottom_up.res4.20.conv1.*              | backbone.bottom_up.res4.20.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,1024,1,1) |\n",
            "| backbone.bottom_up.res4.20.conv2.*              | backbone.bottom_up.res4.20.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,32,3,3)   |\n",
            "| backbone.bottom_up.res4.20.conv3.*              | backbone.bottom_up.res4.20.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,1024,1,1) |\n",
            "| backbone.bottom_up.res4.21.conv1.*              | backbone.bottom_up.res4.21.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,1024,1,1) |\n",
            "| backbone.bottom_up.res4.21.conv2.*              | backbone.bottom_up.res4.21.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,32,3,3)   |\n",
            "| backbone.bottom_up.res4.21.conv3.*              | backbone.bottom_up.res4.21.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,1024,1,1) |\n",
            "| backbone.bottom_up.res4.22.conv1.*              | backbone.bottom_up.res4.22.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,1024,1,1) |\n",
            "| backbone.bottom_up.res4.22.conv2.*              | backbone.bottom_up.res4.22.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,32,3,3)   |\n",
            "| backbone.bottom_up.res4.22.conv3.*              | backbone.bottom_up.res4.22.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,1024,1,1) |\n",
            "| backbone.bottom_up.res4.3.conv1.*               | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,1024,1,1) |\n",
            "| backbone.bottom_up.res4.3.conv2.*               | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,32,3,3)   |\n",
            "| backbone.bottom_up.res4.3.conv3.*               | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,1024,1,1) |\n",
            "| backbone.bottom_up.res4.4.conv1.*               | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,1024,1,1) |\n",
            "| backbone.bottom_up.res4.4.conv2.*               | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,32,3,3)   |\n",
            "| backbone.bottom_up.res4.4.conv3.*               | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,1024,1,1) |\n",
            "| backbone.bottom_up.res4.5.conv1.*               | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,1024,1,1) |\n",
            "| backbone.bottom_up.res4.5.conv2.*               | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,32,3,3)   |\n",
            "| backbone.bottom_up.res4.5.conv3.*               | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,1024,1,1) |\n",
            "| backbone.bottom_up.res4.6.conv1.*               | backbone.bottom_up.res4.6.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,1024,1,1) |\n",
            "| backbone.bottom_up.res4.6.conv2.*               | backbone.bottom_up.res4.6.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,32,3,3)   |\n",
            "| backbone.bottom_up.res4.6.conv3.*               | backbone.bottom_up.res4.6.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,1024,1,1) |\n",
            "| backbone.bottom_up.res4.7.conv1.*               | backbone.bottom_up.res4.7.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,1024,1,1) |\n",
            "| backbone.bottom_up.res4.7.conv2.*               | backbone.bottom_up.res4.7.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,32,3,3)   |\n",
            "| backbone.bottom_up.res4.7.conv3.*               | backbone.bottom_up.res4.7.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,1024,1,1) |\n",
            "| backbone.bottom_up.res4.8.conv1.*               | backbone.bottom_up.res4.8.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,1024,1,1) |\n",
            "| backbone.bottom_up.res4.8.conv2.*               | backbone.bottom_up.res4.8.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,32,3,3)   |\n",
            "| backbone.bottom_up.res4.8.conv3.*               | backbone.bottom_up.res4.8.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,1024,1,1) |\n",
            "| backbone.bottom_up.res4.9.conv1.*               | backbone.bottom_up.res4.9.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,1024,1,1) |\n",
            "| backbone.bottom_up.res4.9.conv2.*               | backbone.bottom_up.res4.9.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,32,3,3)   |\n",
            "| backbone.bottom_up.res4.9.conv3.*               | backbone.bottom_up.res4.9.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,1024,1,1) |\n",
            "| backbone.bottom_up.res5.0.conv1.*               | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
            "| backbone.bottom_up.res5.0.conv2.*               | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,64,3,3)   |\n",
            "| backbone.bottom_up.res5.0.conv3.*               | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,2048,1,1) |\n",
            "| backbone.bottom_up.res5.0.shortcut.*            | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
            "| backbone.bottom_up.res5.1.conv1.*               | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,2048,1,1) |\n",
            "| backbone.bottom_up.res5.1.conv2.*               | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,64,3,3)   |\n",
            "| backbone.bottom_up.res5.1.conv3.*               | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,2048,1,1) |\n",
            "| backbone.bottom_up.res5.2.conv1.*               | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,2048,1,1) |\n",
            "| backbone.bottom_up.res5.2.conv2.*               | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,64,3,3)   |\n",
            "| backbone.bottom_up.res5.2.conv3.*               | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,2048,1,1) |\n",
            "| backbone.bottom_up.stem.conv1.*                 | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
            "| backbone.fpn_lateral2.*                         | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
            "| backbone.fpn_lateral3.*                         | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
            "| backbone.fpn_lateral4.*                         | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
            "| backbone.fpn_lateral5.*                         | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
            "| backbone.fpn_output2.*                          | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
            "| backbone.fpn_output3.*                          | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
            "| backbone.fpn_output4.*                          | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
            "| backbone.fpn_output5.*                          | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
            "| proposal_generator.rpn_head.anchor_deltas.*     | proposal_generator.rpn_head.anchor_deltas.{bias,weight}                                              | (12,) (12,256,1,1)                              |\n",
            "| proposal_generator.rpn_head.conv.*              | proposal_generator.rpn_head.conv.{bias,weight}                                                       | (256,) (256,256,3,3)                            |\n",
            "| proposal_generator.rpn_head.objectness_logits.* | proposal_generator.rpn_head.objectness_logits.{bias,weight}                                          | (3,) (3,256,1,1)                                |\n",
            "| roi_heads.box_head.fc1.*                        | roi_heads.box_head.fc1.{bias,weight}                                                                 | (1024,) (1024,12544)                            |\n",
            "| roi_heads.box_head.fc2.*                        | roi_heads.box_head.fc2.{bias,weight}                                                                 | (1024,) (1024,1024)                             |\n",
            "| roi_heads.box_predictor.bbox_pred.*             | roi_heads.box_predictor.bbox_pred.{bias,weight}                                                      | (12,) (12,1024)                                 |\n",
            "| roi_heads.box_predictor.cls_score.*             | roi_heads.box_predictor.cls_score.{bias,weight}                                                      | (4,) (4,1024)                                   |\n",
            "| roi_heads.mask_head.deconv.*                    | roi_heads.mask_head.deconv.{bias,weight}                                                             | (256,) (256,256,2,2)                            |\n",
            "| roi_heads.mask_head.mask_fcn1.*                 | roi_heads.mask_head.mask_fcn1.{bias,weight}                                                          | (256,) (256,256,3,3)                            |\n",
            "| roi_heads.mask_head.mask_fcn2.*                 | roi_heads.mask_head.mask_fcn2.{bias,weight}                                                          | (256,) (256,256,3,3)                            |\n",
            "| roi_heads.mask_head.mask_fcn3.*                 | roi_heads.mask_head.mask_fcn3.{bias,weight}                                                          | (256,) (256,256,3,3)                            |\n",
            "| roi_heads.mask_head.mask_fcn4.*                 | roi_heads.mask_head.mask_fcn4.{bias,weight}                                                          | (256,) (256,256,3,3)                            |\n",
            "| roi_heads.mask_head.predictor.*                 | roi_heads.mask_head.predictor.{bias,weight}                                                          | (3,) (3,256,1,1)                                |\n"
          ]
        }
      ],
      "source": [
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"best_model.pth\")  # path to the model we just trained\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set a custom testing threshold\n",
        "predictor = DefaultPredictor(cfg)"
      ],
      "id": "T_UukOsW-TIF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1e963236"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from detectron2.utils.visualizer import ColorMode\n",
        "dataset_dicts = DatasetCatalog.get(\"Test\")\n",
        "for d in dataset_dicts:    \n",
        "    im = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor(im)\n",
        "    v = Visualizer(im[:, :, ::-1],\n",
        "                   metadata=MetadataCatalog.get(\"Test\"),\n",
        "                   scale=1, \n",
        "                   instance_mode=ColorMode.IMAGE_BW\n",
        "    )\n",
        "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    im2 = Image.fromarray(out.get_image()[:, :, ::-1])\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(12, 7))\n",
        "    ax[0].imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB)) # original image\n",
        "    ax[1].imshow(im2) # prediction\n",
        "    plt.show()"
      ],
      "id": "1e963236"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALJffJVhJqMG"
      },
      "source": [
        "# Download trained model for future inference"
      ],
      "id": "ALJffJVhJqMG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WsaXovXa5YbP"
      },
      "outputs": [],
      "source": [
        "# convert folder output ke zip\n",
        "from zipfile import ZipFile\n",
        "import os\n",
        "\n",
        "file_path =[]\n",
        "for root, directories, files in os.walk('/content/output'):\n",
        "  for filename in files:\n",
        "    filepath = os.path.join(root, filename)\n",
        "    file_path.append(filepath)\n",
        "\n",
        "with ZipFile('/content/output_X_101_32x8d_FPN_3x.zip', 'w') as zip:\n",
        "  for file in file_path:\n",
        "    zip.write(file)"
      ],
      "id": "WsaXovXa5YbP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "K-ZXMLEUOEVH",
        "outputId": "ea0fce9e-ad0d-4b55-95fe-c7adfdf1a0da"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Dataset_v4/output_X_101_32x8d_FPN_3x.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# copy zip file to drive\n",
        "import shutil\n",
        "shutil.copy(\"/content/output_X_101_32x8d_FPN_3x.zip\",\"/content/drive/MyDrive/Dataset_v4\")"
      ],
      "id": "K-ZXMLEUOEVH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmawZZjWJuoa"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download(os.path.join(cfg.OUTPUT_DIR, \"best_model.pth\"))"
      ],
      "id": "mmawZZjWJuoa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JnA3YSX27ACV"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download(os.path.join('/content/output/output.zip'))"
      ],
      "id": "JnA3YSX27ACV"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}